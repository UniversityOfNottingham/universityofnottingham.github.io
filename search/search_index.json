{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"This site documents Policies , Standards , Guidelines and Processes for Software Development in use at the University of Nottingham . Who is it for? The content of this site should be considered: mandatory for the Product Centre Application Development team. with the exception of recommended-only Guidelines . recommended to other developers at the University. of interest to external software development parties. Glossary of terms \u00b6 Main Terms \u00b6 Term Definition Policies Brief formal statements that describe a mandatory action or behaviour, along with its purpose and desired results. Standards Decribe the tools, technologies and expected behavour used to comply with Policies . Guidelines Make recommendations and provide guidance instructions on how to follow Standards . Processes Describe the exact implementation of Policies , following Standards and Guidelines . They describe who does what, when and how. Internal Processes Many University of Nottingham Software Development Processes are internal only, and so these Processes and the Guidelines that correspond to them are not detailed on this site. They may be found here by authorised parties (such as the Product Centre Application Development team). What's not here? \u00b6 The site is a work in progress, so some areas that you feel should have documentation may be planned for the future. Notably, this site does not provide documentation for: Anything that should remain internal to the University. Documentation for these things can be found on a private internal docs site. Documentation for individual applications produced by the University. These applications should have general documentation contained within their source repositories. On GitHub this documentation may be published as a GitHub Pages site. Internally this documentation may be published on an internal docs site. These applications may also have instance specific documentation which will be held internally to the University by the Service Management team. Contributing to this documentation \u00b6 Refer to the site's Git repository .","title":"Home"},{"location":"#glossary-of-terms","text":"","title":"Glossary of terms"},{"location":"#main-terms","text":"Term Definition Policies Brief formal statements that describe a mandatory action or behaviour, along with its purpose and desired results. Standards Decribe the tools, technologies and expected behavour used to comply with Policies . Guidelines Make recommendations and provide guidance instructions on how to follow Standards . Processes Describe the exact implementation of Policies , following Standards and Guidelines . They describe who does what, when and how. Internal Processes Many University of Nottingham Software Development Processes are internal only, and so these Processes and the Guidelines that correspond to them are not detailed on this site. They may be found here by authorised parties (such as the Product Centre Application Development team).","title":"Main Terms"},{"location":"#whats-not-here","text":"The site is a work in progress, so some areas that you feel should have documentation may be planned for the future. Notably, this site does not provide documentation for: Anything that should remain internal to the University. Documentation for these things can be found on a private internal docs site. Documentation for individual applications produced by the University. These applications should have general documentation contained within their source repositories. On GitHub this documentation may be published as a GitHub Pages site. Internally this documentation may be published on an internal docs site. These applications may also have instance specific documentation which will be held internally to the University by the Service Management team.","title":"What's not here?"},{"location":"#contributing-to-this-documentation","text":"Refer to the site's Git repository .","title":"Contributing to this documentation"},{"location":"policies/","text":"What are Policies? Policies are brief formal statements that describe a mandatory action or behaviour, along with its purpose and desired results. The homepage has a glossary of associated terms. 1. Code Quality and Style \u00b6 1.0.1 We write high quality code. Ensuring the quality of our code is both consistent and to a high standard makes the following easier: To have confidence that our code will perform as expected. For any developer (even those not familiar with the codebase) to maintain the code, or extend it. 1.0.2 We write code in a consistent style. Ensuring the style of our code is both consistent and follows accepted conventions makes the following easier: For any developer (even those not familiar with the codebase) to maintain the code, or extend it. For third party documentation and guidance to be more likely to be directly useful. 1.0.3 We use tooling to enforce quality and style. Ensuring we use tooling and automated processes wherever possible to enforce code quality and style makes the following easier: To be confident that quality and style will be as intended. To avoid having to manually document quality and style rules. To avoid having to manually ensure code meets quality and style rules. To avoid arguments over quality and style rules. 1.1 Code Comments \u00b6 1.1.1 We use doc comments to document code. Ensuring we use conventional documentation comments wherever possible makes the following easier: To be confident our code's behaviour and intention is well understood. For any developer (even those not familiar with the codebase) to maintain the code, or extend it. To produce API documentation sites automatically. 1.1.2 We use task comments to indicate work to be done. Ensuring we use task comments such as TODO: and HACK: to indicate work to be done makes the following easier: To track work to be done at a location within the codebase. Many editors support highlighting or listing outstanding tasks. To indicate why a sub-optimal or questionable practice is temporary. 1.1.3 We use code comments to explain unexpected or complex behaviour. Ensuring we use comments to document unexpected behaviour, unconventional (but necessary) approaches, or complex code makes the following easier: To be confident our code's behaviour and intention is well understood. For any developer (even those not familiar with the codebase) to maintain the code, or extend it. 1.1.4 We don't comment code where behaviour is clear. Ensuring we don't comment code where the code's behaviour and intention are already clear makes the following easier: To read large methods which have clear, readable behaviour. Unnecessary comments would provide noise. To save time. No need to type an explanation for something that is self-explanatory. To encourage clear code. Good code is self-documenting (to a degree) and so developers should try and write code that is clear enough without comments whenever possible. 1.2 Structure \u00b6 1.2.1 We follow common conventional architectural structures, like MVC. Ensuring our applications are structured architecturally following common conventions , such as MVC and its derivatives, makes the following easier: For any developer (even those not familiar with the codebase) to maintain the code, or extend it. 2. Target Platforms \u00b6 2.1 We target a specific limited set of approved platforms. Ensuring we write code for a specific set of approved platforms makes the following easier: For any developer (even those not familiar with the codebase) to maintain the code, or extend it. To focus training needs within the confines of those platforms. To avoid unnecessary proliferation of technologies. 2.2 We build web apps. Ensuring we build web applications whenever possible makes the following easier: To avoid dependencies on specific client runtime environments. To avoid the need to update the application to work with newer or different client runtime environments. 3. Source / Version Control \u00b6 3.1 We use a distributed version control system. Ensuring we use a distributed version control system to manage our codebase makes the following easier: To be confident that code changes are broken down into small manageable chunks. To be comfortable making experimental code changes in isolation from the stable branch. To manage the release of changes to production. To be confident that code is in multiple locations, with no single point of failure to cause loss of work. 3.2 We use a clearly defined branching workflow. Ensuring we use a clearly defined and conventional branching workflow makes the following easier: To manage the release of changes to production. For any developer (even those not familiar with the codebase) to maintain the code, or extend it. 4. Versioning \u00b6 4.1 We use a clearly defined versioning system that conveys semantic information. Ensuring we use a clearly defined system for versioning software that conveys semantic information about the changes in a version makes the following easier: For developers to know when to version bump software, and to what version. For people to understand the implications of a change from one version to another. 4.2 We use a clearly defined versioning system suitable for continuous releases. Ensuring we use a clearly defined system for versioning software that is suitable for continuous releases makes the following easier: For developers and testers to refer to a specific release, regardless of whether it is otherwise semantically different to another release. For automated tooling to appropriately version releases. 5. Code Reviews \u00b6 5.1 We peer review code changes. Ensuring we peer review code changes makes the following easier: To be confident that code is meeting Standards and complying with Policies . To discuss and advise on implementations or designs. To share knowledge between team members. To ensure implementations are appropriate for a given project's requirements. 5.2 We support reviews with automated tooling. Ensuring that we use automated tooling to assist with code reviews makes the following easier: For developers to not manually have to check that code is compliant with Policies . To be confident that the code is in a state to be reviewed and merged. 6. Continuous Integration \u00b6 6.1 We use Continuous Integration services to regularly build code. Ensuring that we regularly build changes to our code using automated services makes the following easier: For developers to be confident that their changes build. To avoid the need to manually run builds regularly, or for reviews. To be confident of the quality of delivered releases. 6.2 We use Continuous Integration services to run tests automatically. Ensuring that we automatically test changes to our code whenever we build it makes the following easier: For developers to be confident that their changes have not broken tests. To avoid the need to manually run tests for reviews. To be confident of the quality of delivered releases. 6.3 We use Continuous Integration services to release software. Ensuring that we release our software using the same automated tools we used to build and test makes the following easier: To be confident we are releasing the exact same code that was successfully built and tested. To avoid manual steps in releases. To guarantee that repeatable release tasks are done the same way every time. To provide a clear audit trail of releases to environments, of specific code versions. To be confident of the quality of delivered releases.","title":"Policies"},{"location":"policies/#1-code-quality-and-style","text":"1.0.1 We write high quality code. Ensuring the quality of our code is both consistent and to a high standard makes the following easier: To have confidence that our code will perform as expected. For any developer (even those not familiar with the codebase) to maintain the code, or extend it. 1.0.2 We write code in a consistent style. Ensuring the style of our code is both consistent and follows accepted conventions makes the following easier: For any developer (even those not familiar with the codebase) to maintain the code, or extend it. For third party documentation and guidance to be more likely to be directly useful. 1.0.3 We use tooling to enforce quality and style. Ensuring we use tooling and automated processes wherever possible to enforce code quality and style makes the following easier: To be confident that quality and style will be as intended. To avoid having to manually document quality and style rules. To avoid having to manually ensure code meets quality and style rules. To avoid arguments over quality and style rules.","title":"1. Code Quality and Style"},{"location":"policies/#11-code-comments","text":"1.1.1 We use doc comments to document code. Ensuring we use conventional documentation comments wherever possible makes the following easier: To be confident our code's behaviour and intention is well understood. For any developer (even those not familiar with the codebase) to maintain the code, or extend it. To produce API documentation sites automatically. 1.1.2 We use task comments to indicate work to be done. Ensuring we use task comments such as TODO: and HACK: to indicate work to be done makes the following easier: To track work to be done at a location within the codebase. Many editors support highlighting or listing outstanding tasks. To indicate why a sub-optimal or questionable practice is temporary. 1.1.3 We use code comments to explain unexpected or complex behaviour. Ensuring we use comments to document unexpected behaviour, unconventional (but necessary) approaches, or complex code makes the following easier: To be confident our code's behaviour and intention is well understood. For any developer (even those not familiar with the codebase) to maintain the code, or extend it. 1.1.4 We don't comment code where behaviour is clear. Ensuring we don't comment code where the code's behaviour and intention are already clear makes the following easier: To read large methods which have clear, readable behaviour. Unnecessary comments would provide noise. To save time. No need to type an explanation for something that is self-explanatory. To encourage clear code. Good code is self-documenting (to a degree) and so developers should try and write code that is clear enough without comments whenever possible.","title":"1.1 Code Comments"},{"location":"policies/#12-structure","text":"1.2.1 We follow common conventional architectural structures, like MVC. Ensuring our applications are structured architecturally following common conventions , such as MVC and its derivatives, makes the following easier: For any developer (even those not familiar with the codebase) to maintain the code, or extend it.","title":"1.2 Structure"},{"location":"policies/#2-target-platforms","text":"2.1 We target a specific limited set of approved platforms. Ensuring we write code for a specific set of approved platforms makes the following easier: For any developer (even those not familiar with the codebase) to maintain the code, or extend it. To focus training needs within the confines of those platforms. To avoid unnecessary proliferation of technologies. 2.2 We build web apps. Ensuring we build web applications whenever possible makes the following easier: To avoid dependencies on specific client runtime environments. To avoid the need to update the application to work with newer or different client runtime environments.","title":"2. Target Platforms"},{"location":"policies/#3-source-version-control","text":"3.1 We use a distributed version control system. Ensuring we use a distributed version control system to manage our codebase makes the following easier: To be confident that code changes are broken down into small manageable chunks. To be comfortable making experimental code changes in isolation from the stable branch. To manage the release of changes to production. To be confident that code is in multiple locations, with no single point of failure to cause loss of work. 3.2 We use a clearly defined branching workflow. Ensuring we use a clearly defined and conventional branching workflow makes the following easier: To manage the release of changes to production. For any developer (even those not familiar with the codebase) to maintain the code, or extend it.","title":"3. Source / Version Control"},{"location":"policies/#4-versioning","text":"4.1 We use a clearly defined versioning system that conveys semantic information. Ensuring we use a clearly defined system for versioning software that conveys semantic information about the changes in a version makes the following easier: For developers to know when to version bump software, and to what version. For people to understand the implications of a change from one version to another. 4.2 We use a clearly defined versioning system suitable for continuous releases. Ensuring we use a clearly defined system for versioning software that is suitable for continuous releases makes the following easier: For developers and testers to refer to a specific release, regardless of whether it is otherwise semantically different to another release. For automated tooling to appropriately version releases.","title":"4. Versioning"},{"location":"policies/#5-code-reviews","text":"5.1 We peer review code changes. Ensuring we peer review code changes makes the following easier: To be confident that code is meeting Standards and complying with Policies . To discuss and advise on implementations or designs. To share knowledge between team members. To ensure implementations are appropriate for a given project's requirements. 5.2 We support reviews with automated tooling. Ensuring that we use automated tooling to assist with code reviews makes the following easier: For developers to not manually have to check that code is compliant with Policies . To be confident that the code is in a state to be reviewed and merged.","title":"5. Code Reviews"},{"location":"policies/#6-continuous-integration","text":"6.1 We use Continuous Integration services to regularly build code. Ensuring that we regularly build changes to our code using automated services makes the following easier: For developers to be confident that their changes build. To avoid the need to manually run builds regularly, or for reviews. To be confident of the quality of delivered releases. 6.2 We use Continuous Integration services to run tests automatically. Ensuring that we automatically test changes to our code whenever we build it makes the following easier: For developers to be confident that their changes have not broken tests. To avoid the need to manually run tests for reviews. To be confident of the quality of delivered releases. 6.3 We use Continuous Integration services to release software. Ensuring that we release our software using the same automated tools we used to build and test makes the following easier: To be confident we are releasing the exact same code that was successfully built and tested. To avoid manual steps in releases. To guarantee that repeatable release tasks are done the same way every time. To provide a clear audit trail of releases to environments, of specific code versions. To be confident of the quality of delivered releases.","title":"6. Continuous Integration"},{"location":"guidelines/packages/","text":"TODO - this requires more work Guide to publishing packages on NuGet Guide to publishing packages on NPM","title":"Packages"},{"location":"guidelines/recommended-tools/","text":"Git \u00b6 As per our Standards , we use Git for version control. You are welcome to use any git client you're comfortable with, but we recommend GitKraken . GitKraken features: Cross-platform (Windows, Mac, Linux) Modern Supports Git Flow Connects directly to several Git hosting services, including GitHub Text Editor \u00b6 We recommend installing a decent text editor rather than using notepad forever. This is obviously personal preference, but if you're looking for suggestions, the following editors are popular and useful: Visual Studio Code (Windows, Mac, Linux) Atom (Windows, Mac, Linux) Notepad++ (Windows) REST / HTTP client \u00b6 If you find yourself needing to test APIs, you'll want a client designed to do that. Postman (Windows, Mac, Chrome App) Insomnia (Windows, Mac, Linux)","title":"Recommended Tools"},{"location":"guidelines/recommended-tools/#git","text":"As per our Standards , we use Git for version control. You are welcome to use any git client you're comfortable with, but we recommend GitKraken . GitKraken features: Cross-platform (Windows, Mac, Linux) Modern Supports Git Flow Connects directly to several Git hosting services, including GitHub","title":"Git"},{"location":"guidelines/recommended-tools/#text-editor","text":"We recommend installing a decent text editor rather than using notepad forever. This is obviously personal preference, but if you're looking for suggestions, the following editors are popular and useful: Visual Studio Code (Windows, Mac, Linux) Atom (Windows, Mac, Linux) Notepad++ (Windows)","title":"Text Editor"},{"location":"guidelines/recommended-tools/#rest-http-client","text":"If you find yourself needing to test APIs, you'll want a client designed to do that. Postman (Windows, Mac, Chrome App) Insomnia (Windows, Mac, Linux)","title":"REST / HTTP client"},{"location":"guidelines/repository-creation/","text":"1. Create the Repository \u00b6 In the Azure DevOps menu, navigate to the Repos page. From the drop-down where you can select an existing repository, select New Repository (or from the + menu near the top left of the screen, select New repository ). TODO - Standards for Naming Repos Check the box to add a README , and add a .gitignore (e.g. for Visual Studio projects, select Visual Studio from the dropdown). Click Create . 2. Set Branch Policies for master \u00b6 With your new repo still selected, navigate to the Branches sub-menu. On the row for the master branch, from the More Actions context menu (next to the Commit number), select Branch Policies . Tick the following options: Require a minimum number of reviewers (set the minimum number as required by team standards) Reset code reviewer votes when there are new changes Check for linked work items (select Optional ) Check for comment resolution (select Required ) Under Automatically include code reviewers , click the button to Add automatic reviewers . Under Reviewer(s) , search for Application Development and choose the search result with the [UniversityofNottingham] prefix. Select a Policy requirement of Required for this reviewer, and click Save . 3. Create a Pipeline \u00b6 In the Azure DevOps menu, navigate to the Pipelines page, and at the top right click the New pipeline button. Click on Azure Repos Git , then filter and select your repository. Select Starter pipeline . Replace the pipeline YAML with the following: # Starter pipeline # Start with a minimal pipeline that you can customize to build and deploy your code. # Add steps that build, run tests, deploy, and more: # https://aka.ms/yaml trigger : - master pool : name : Default steps : - script : '|' Click the button at top right to Save and run the pipeline. Select the option to Create a new branch for this commit and start a pull request , then click the button to Save and run . The build will fail, because of the change we made to the pipeline YAML file. This is by design: at this point, we want a failing pipeline build in order to ensure that later, when a project is created, a suitable, passing, code-reviewed pipeline build step, appropriate for the project type (rather than the default, generic, always-passing pipeline build steps) must be added to the pipeline YAML in order to merge the project into master. The pull request now needs to be reviewed and approved, to merge the pipeline YAML to master. 4. Add a Build Policy for merges to master \u00b6 In Azure DevOps, navigate to the Repos menu, make sure your new repo is still selected, and navigate to the Branches sub-menu. On the row for the master branch, from the More Actions context menu (next to the Commit number), select Branch Policies . Under the Build validation section, click the button to Add build policy . Select the Build Pipeline you created in the previous step (the name should be the same as the name of the repo). Keep the default options: Trigger: Automatic Policy requirement: Required Build expiration: After 12 hours if master has been updated 5. Create your solution \u00b6 Clone the Repo. Create a branch. Create your initial bare-bones project/solution within that branch. Make sure to edit the pipeline YAML file to define the appropriate build step(s) and demands. For example, for a dotnet sdk project, the following specifies a dotnet build step, and demands that the server chosen from the Default pool to perform the build must have dotnet : trigger : - master pool : name : Default demands : dotnet steps : - script : 'dotnet build' Finally, push all your changes and make a pull request to merge your branch to master .","title":"Creating a Repository in Azure DevOps"},{"location":"guidelines/repository-creation/#1-create-the-repository","text":"In the Azure DevOps menu, navigate to the Repos page. From the drop-down where you can select an existing repository, select New Repository (or from the + menu near the top left of the screen, select New repository ). TODO - Standards for Naming Repos Check the box to add a README , and add a .gitignore (e.g. for Visual Studio projects, select Visual Studio from the dropdown). Click Create .","title":"1. Create the Repository"},{"location":"guidelines/repository-creation/#2-set-branch-policies-for-master","text":"With your new repo still selected, navigate to the Branches sub-menu. On the row for the master branch, from the More Actions context menu (next to the Commit number), select Branch Policies . Tick the following options: Require a minimum number of reviewers (set the minimum number as required by team standards) Reset code reviewer votes when there are new changes Check for linked work items (select Optional ) Check for comment resolution (select Required ) Under Automatically include code reviewers , click the button to Add automatic reviewers . Under Reviewer(s) , search for Application Development and choose the search result with the [UniversityofNottingham] prefix. Select a Policy requirement of Required for this reviewer, and click Save .","title":"2. Set Branch Policies for master"},{"location":"guidelines/repository-creation/#3-create-a-pipeline","text":"In the Azure DevOps menu, navigate to the Pipelines page, and at the top right click the New pipeline button. Click on Azure Repos Git , then filter and select your repository. Select Starter pipeline . Replace the pipeline YAML with the following: # Starter pipeline # Start with a minimal pipeline that you can customize to build and deploy your code. # Add steps that build, run tests, deploy, and more: # https://aka.ms/yaml trigger : - master pool : name : Default steps : - script : '|' Click the button at top right to Save and run the pipeline. Select the option to Create a new branch for this commit and start a pull request , then click the button to Save and run . The build will fail, because of the change we made to the pipeline YAML file. This is by design: at this point, we want a failing pipeline build in order to ensure that later, when a project is created, a suitable, passing, code-reviewed pipeline build step, appropriate for the project type (rather than the default, generic, always-passing pipeline build steps) must be added to the pipeline YAML in order to merge the project into master. The pull request now needs to be reviewed and approved, to merge the pipeline YAML to master.","title":"3. Create a Pipeline"},{"location":"guidelines/repository-creation/#4-add-a-build-policy-for-merges-to-master","text":"In Azure DevOps, navigate to the Repos menu, make sure your new repo is still selected, and navigate to the Branches sub-menu. On the row for the master branch, from the More Actions context menu (next to the Commit number), select Branch Policies . Under the Build validation section, click the button to Add build policy . Select the Build Pipeline you created in the previous step (the name should be the same as the name of the repo). Keep the default options: Trigger: Automatic Policy requirement: Required Build expiration: After 12 hours if master has been updated","title":"4. Add a Build Policy for merges to master"},{"location":"guidelines/repository-creation/#5-create-your-solution","text":"Clone the Repo. Create a branch. Create your initial bare-bones project/solution within that branch. Make sure to edit the pipeline YAML file to define the appropriate build step(s) and demands. For example, for a dotnet sdk project, the following specifies a dotnet build step, and demands that the server chosen from the Default pool to perform the build must have dotnet : trigger : - master pool : name : Default demands : dotnet steps : - script : 'dotnet build' Finally, push all your changes and make a pull request to merge your branch to master .","title":"5. Create your solution"},{"location":"guidelines/azure-devops-scrum/","text":"Using Azure DevOps for Agile (SCRUM) Development \u00b6 This documentation is intended to help guide and support the use of Azure DevOps and SCRUM at UoN SCRUM Guide \u00b6 Anyone involved in SCRUM should be aware of the contents and ideas contained within the SCRUM Guides. Please click here for a download SCRUM Presentation \u00b6 Here's a Powerpoint presentation on SCRUM Hope it's useful Please click here for a download Microsoft Excel Integration \u00b6 Azure DevOps can happily co-exist with Excel - if the 'Teams' menu does not appear on your ribbon, install VS Team Explorer from here and the 'team' tab appeared in Excel","title":"Overview"},{"location":"guidelines/azure-devops-scrum/#using-azure-devops-for-agile-scrum-development","text":"This documentation is intended to help guide and support the use of Azure DevOps and SCRUM at UoN","title":"Using Azure DevOps for Agile (SCRUM) Development"},{"location":"guidelines/azure-devops-scrum/#scrum-guide","text":"Anyone involved in SCRUM should be aware of the contents and ideas contained within the SCRUM Guides. Please click here for a download","title":"SCRUM Guide"},{"location":"guidelines/azure-devops-scrum/#scrum-presentation","text":"Here's a Powerpoint presentation on SCRUM Hope it's useful Please click here for a download","title":"SCRUM Presentation"},{"location":"guidelines/azure-devops-scrum/#microsoft-excel-integration","text":"Azure DevOps can happily co-exist with Excel - if the 'Teams' menu does not appear on your ribbon, install VS Team Explorer from here and the 'team' tab appeared in Excel","title":"Microsoft Excel Integration"},{"location":"guidelines/azure-devops-scrum/azure-devops-setup/","text":"Azure DevOps Workstream Setup (Teams) and General Admin \u00b6 In order to cross-report, move items between teams and for ease of setup; all UoN workstreams are completed within the same 'project' - namely 'ProductCentre.Main'. Why? Read this and then this Setup a Backlog \u00b6 As all teams are hanging off the same project, you'll need to setup a backlog for the team under the ProductCentre.Main iteration. Click here; https://dev.azure.com/UniversityOfNottingham/ProductCentre.Main/_admin/_Work?_a=iterations Right click on ProductCentre.Main and select 'Add Child'. Give your iteration a meaningful name ensuring it ends with the word 'backlog' - again, this is important later in the process to be able to identify the difference between a backlog and an area. Setup Sprints (Iterations) \u00b6 Finally, we can start adding sprints. Again, right click on the newly created backlog, and 'New Child'. Start adding your sprints as required. Setting up teams \u00b6 We utilise the Azure DevOps 'Team' setup in order to manage and run our projects. Each 'team' will have its own backlog, kanban and time tracking area and should be setup when a new 'project' is starting. From with ProductCentre.Main , click the access menu and select 'New Team' Complete the 'Create new team' information page and click 'Create team' when ready - You'll then be redirected to the newly created area specifically for your team. Adding Team Members \u00b6 Next, you'll need to add team members to the project. Adding the team in here is important for a couple of reasons. Besides the obvious, to show who's on the project, but it's to speed up the assigning of tasks at a later point and, in the case of non-Product Centre users, to give them access rights to view the detail within. From the menu ribbon, click the cog. This will open the 'Overview' page. Then, select the 'Add...' option and begin to build your team. Localisation \u00b6 If your Azure DevOps is appearing with American datetime settings, click on your initials or profile image in the top right of Azure DevOps and select 'My Profile'. On the next screen, select the 'Edit Profile' option. Finally, click 'Preferences' and change the date pattern and time zone as required. Setup Project - which you shouldn't do \u00b6 For completness, this is how you setup a new project... which you shouldn't... but this is how: New projects are setup from the admin page. Direct link is: https://dev.azure.com/UniversityOfNottingham/_projects?_a=new . Once you've given the new project a title and description, click Create; A project area is created by default and associated with the project. The workstream lead creating the project automatically becomes a member of the project - however additional members will need to be added. From the cog icon at the top, select 'Default Team Settings' Then, build up your team by selecting 'Add', type in the surname of the team members, select them, and finally click 'Save Changes'.","title":"Azure DevOps Setup"},{"location":"guidelines/azure-devops-scrum/azure-devops-setup/#azure-devops-workstream-setup-teams-and-general-admin","text":"In order to cross-report, move items between teams and for ease of setup; all UoN workstreams are completed within the same 'project' - namely 'ProductCentre.Main'. Why? Read this and then this","title":"Azure DevOps Workstream Setup (Teams) and General Admin"},{"location":"guidelines/azure-devops-scrum/azure-devops-setup/#setup-a-backlog","text":"As all teams are hanging off the same project, you'll need to setup a backlog for the team under the ProductCentre.Main iteration. Click here; https://dev.azure.com/UniversityOfNottingham/ProductCentre.Main/_admin/_Work?_a=iterations Right click on ProductCentre.Main and select 'Add Child'. Give your iteration a meaningful name ensuring it ends with the word 'backlog' - again, this is important later in the process to be able to identify the difference between a backlog and an area.","title":"Setup a Backlog"},{"location":"guidelines/azure-devops-scrum/azure-devops-setup/#setup-sprints-iterations","text":"Finally, we can start adding sprints. Again, right click on the newly created backlog, and 'New Child'. Start adding your sprints as required.","title":"Setup Sprints (Iterations)"},{"location":"guidelines/azure-devops-scrum/azure-devops-setup/#setting-up-teams","text":"We utilise the Azure DevOps 'Team' setup in order to manage and run our projects. Each 'team' will have its own backlog, kanban and time tracking area and should be setup when a new 'project' is starting. From with ProductCentre.Main , click the access menu and select 'New Team' Complete the 'Create new team' information page and click 'Create team' when ready - You'll then be redirected to the newly created area specifically for your team.","title":"Setting up teams"},{"location":"guidelines/azure-devops-scrum/azure-devops-setup/#adding-team-members","text":"Next, you'll need to add team members to the project. Adding the team in here is important for a couple of reasons. Besides the obvious, to show who's on the project, but it's to speed up the assigning of tasks at a later point and, in the case of non-Product Centre users, to give them access rights to view the detail within. From the menu ribbon, click the cog. This will open the 'Overview' page. Then, select the 'Add...' option and begin to build your team.","title":"Adding Team Members"},{"location":"guidelines/azure-devops-scrum/azure-devops-setup/#localisation","text":"If your Azure DevOps is appearing with American datetime settings, click on your initials or profile image in the top right of Azure DevOps and select 'My Profile'. On the next screen, select the 'Edit Profile' option. Finally, click 'Preferences' and change the date pattern and time zone as required.","title":"Localisation"},{"location":"guidelines/azure-devops-scrum/azure-devops-setup/#setup-project-which-you-shouldnt-do","text":"For completness, this is how you setup a new project... which you shouldn't... but this is how: New projects are setup from the admin page. Direct link is: https://dev.azure.com/UniversityOfNottingham/_projects?_a=new . Once you've given the new project a title and description, click Create; A project area is created by default and associated with the project. The workstream lead creating the project automatically becomes a member of the project - however additional members will need to be added. From the cog icon at the top, select 'Default Team Settings' Then, build up your team by selecting 'Add', type in the surname of the team members, select them, and finally click 'Save Changes'.","title":"Setup Project - which you shouldn't do"},{"location":"guidelines/azure-devops-scrum/azure-devops/","text":"Azure DevOps Setup and Usages \u00b6 Introduction \u00b6 This document is intended to be used by University of Nottingham's Development Teams migrating to TFS for use of Task Management and, in a later phase, Source Code Management (SCM). These guidelines are industry standards and should be followed by everyone in the development team to develop a vision and sustainable approach by which the University of Nottingham can prioritise IT investments that fuel business growth. Azure DevOps web access can be accessed here; https://dev.azure.com/UniversityOfNottingham . Project and Collection Architecture \u00b6 We will utilse Microsoft's offering of using Team Services, which can host all of the server-side aspects of Azure DevOps. Our work items and team features are all hosted in the cloud - and we'll look to migrate source code and build configurations in later phases. From an architectural point of view, this greatly simplifies your use of Azure DevOps, as the only aspects of the architecture we need to consider are the client components and their Internet access. As for licences, all developers are covered as they use an MSDN. Licences are disucssed further later in this document. When using the Team Services, you use a web browser to connect to the service using your Microsoft account. You can create team projects, add members to your team, and work as you would with a locally installed TFS, without the overhead of administering the servers. Team Services hosts your application tier, data tier, and build servers in the cloud. SCRUM Template \u00b6 The University of Nottingham will use a single SCRUM template slightly modified for reporting purposes. This is the UoN SCRUM (v1.0) process template. Teams \u00b6 Inside a project, there can be a number of teams. These can be used to segment the work item backlog for the various projects. For the purpose of University of Nottingham, each internal 'Project' will equate to a Azure DevOps 'Team' and hence each University of Nottingham Project will be given its own iteration backlog, and any release/milestone/sprint sub iterations required. Any given project, whether it uses a single system or has cross cutting concerns, can be setup as a Azure DevOps Team with its own backlog and sprint iterations. A hierarchy of Teams can be created, so each University of Nottingham project could potentially have many teams each with their own Product Backlog, then roll-up into the parent team for that sub-project like Mobile, Integration, etc These 'Projects' should only be created by the Project Workstream Lead identified during the Project initialisation phase. See 'Setting up projects' section for further details Security and Privileges \u00b6 Access Rights on Azure DevOps \u00b6 Work Item Tracking \u00b6 Free users (access level: Stakeholder) Team Services users (access level: Basic) Create and edit work items, including bugs, requirements , and tasks \u2714 \u2714 Search and query work items \u2714 \u2714 View backlogs and boards \u2714 \u2714 Provide feedback \u2714 \u2714 Request feedback \u2714 Agile tools (Kanban boards, backlogs, sprint planning, portfolio management) \u2714 Code \u00b6 Free users (access level: Stakeholder) Team Services users (access level: Basic) Unlimited private Git repositories \u2714 Connect to your code using Xcode, Eclipse, IntelliJ, Android Studio, Visual Studio, Visual Studio Code, and more \u2714 Centralized version control with TFVC, including Code Review \u2714 Powerful semantic code search \u2714 Build and release \u2714 Continuous deployment with Release Management \u2714 Approve releases \u2714 \u2714 Package Management \u2714 Test \u00b6 Free users (access level: Stakeholder) Team Services users (access level: Basic) Exploratory testing \u2714 Test Manager (purchased separately) \u2714 Other features \u00b6 Free users (access level: Stakeholder) Team Services users (access level: Basic) View charts, widgets, and dashboards \u2714 \u2714 Create charts, configure widgets, and set up dashboards \u2714 Stakeholder \u00b6 This will be the default access right for anyone not registered as a user on Azure DevOps. All Business Users including Project Managers and BAs will have stakeholder access. With Stakeholder access, users can create and modify all work items, and can create and save queries on all work items under their My Queries folder. Basic \u00b6 Developers will have basic access that allows them to manage work items and use Kanban board Anyone upgraded to Basic access should have a valid MSDN License Access rights on Projects \u00b6 Team Members working on a specific project or work package will be added to the Project Team by the Workstream Lead. They will then have ability to work on work items and track the progress. See 'Project setup and admin' section for further details.","title":"Azure DevOps"},{"location":"guidelines/azure-devops-scrum/azure-devops/#azure-devops-setup-and-usages","text":"","title":"Azure DevOps Setup and Usages"},{"location":"guidelines/azure-devops-scrum/azure-devops/#introduction","text":"This document is intended to be used by University of Nottingham's Development Teams migrating to TFS for use of Task Management and, in a later phase, Source Code Management (SCM). These guidelines are industry standards and should be followed by everyone in the development team to develop a vision and sustainable approach by which the University of Nottingham can prioritise IT investments that fuel business growth. Azure DevOps web access can be accessed here; https://dev.azure.com/UniversityOfNottingham .","title":"Introduction"},{"location":"guidelines/azure-devops-scrum/azure-devops/#project-and-collection-architecture","text":"We will utilse Microsoft's offering of using Team Services, which can host all of the server-side aspects of Azure DevOps. Our work items and team features are all hosted in the cloud - and we'll look to migrate source code and build configurations in later phases. From an architectural point of view, this greatly simplifies your use of Azure DevOps, as the only aspects of the architecture we need to consider are the client components and their Internet access. As for licences, all developers are covered as they use an MSDN. Licences are disucssed further later in this document. When using the Team Services, you use a web browser to connect to the service using your Microsoft account. You can create team projects, add members to your team, and work as you would with a locally installed TFS, without the overhead of administering the servers. Team Services hosts your application tier, data tier, and build servers in the cloud.","title":"Project and Collection Architecture"},{"location":"guidelines/azure-devops-scrum/azure-devops/#scrum-template","text":"The University of Nottingham will use a single SCRUM template slightly modified for reporting purposes. This is the UoN SCRUM (v1.0) process template.","title":"SCRUM Template"},{"location":"guidelines/azure-devops-scrum/azure-devops/#teams","text":"Inside a project, there can be a number of teams. These can be used to segment the work item backlog for the various projects. For the purpose of University of Nottingham, each internal 'Project' will equate to a Azure DevOps 'Team' and hence each University of Nottingham Project will be given its own iteration backlog, and any release/milestone/sprint sub iterations required. Any given project, whether it uses a single system or has cross cutting concerns, can be setup as a Azure DevOps Team with its own backlog and sprint iterations. A hierarchy of Teams can be created, so each University of Nottingham project could potentially have many teams each with their own Product Backlog, then roll-up into the parent team for that sub-project like Mobile, Integration, etc These 'Projects' should only be created by the Project Workstream Lead identified during the Project initialisation phase. See 'Setting up projects' section for further details","title":"Teams"},{"location":"guidelines/azure-devops-scrum/azure-devops/#security-and-privileges","text":"","title":"Security and Privileges"},{"location":"guidelines/azure-devops-scrum/azure-devops/#access-rights-on-azure-devops","text":"","title":"Access Rights on Azure DevOps"},{"location":"guidelines/azure-devops-scrum/azure-devops/#work-item-tracking","text":"Free users (access level: Stakeholder) Team Services users (access level: Basic) Create and edit work items, including bugs, requirements , and tasks \u2714 \u2714 Search and query work items \u2714 \u2714 View backlogs and boards \u2714 \u2714 Provide feedback \u2714 \u2714 Request feedback \u2714 Agile tools (Kanban boards, backlogs, sprint planning, portfolio management) \u2714","title":"Work Item Tracking"},{"location":"guidelines/azure-devops-scrum/azure-devops/#code","text":"Free users (access level: Stakeholder) Team Services users (access level: Basic) Unlimited private Git repositories \u2714 Connect to your code using Xcode, Eclipse, IntelliJ, Android Studio, Visual Studio, Visual Studio Code, and more \u2714 Centralized version control with TFVC, including Code Review \u2714 Powerful semantic code search \u2714 Build and release \u2714 Continuous deployment with Release Management \u2714 Approve releases \u2714 \u2714 Package Management \u2714","title":"Code"},{"location":"guidelines/azure-devops-scrum/azure-devops/#test","text":"Free users (access level: Stakeholder) Team Services users (access level: Basic) Exploratory testing \u2714 Test Manager (purchased separately) \u2714","title":"Test"},{"location":"guidelines/azure-devops-scrum/azure-devops/#other-features","text":"Free users (access level: Stakeholder) Team Services users (access level: Basic) View charts, widgets, and dashboards \u2714 \u2714 Create charts, configure widgets, and set up dashboards \u2714","title":"Other features"},{"location":"guidelines/azure-devops-scrum/azure-devops/#stakeholder","text":"This will be the default access right for anyone not registered as a user on Azure DevOps. All Business Users including Project Managers and BAs will have stakeholder access. With Stakeholder access, users can create and modify all work items, and can create and save queries on all work items under their My Queries folder.","title":"Stakeholder"},{"location":"guidelines/azure-devops-scrum/azure-devops/#basic","text":"Developers will have basic access that allows them to manage work items and use Kanban board Anyone upgraded to Basic access should have a valid MSDN License","title":"Basic"},{"location":"guidelines/azure-devops-scrum/azure-devops/#access-rights-on-projects","text":"Team Members working on a specific project or work package will be added to the Project Team by the Workstream Lead. They will then have ability to work on work items and track the progress. See 'Project setup and admin' section for further details.","title":"Access rights on Projects"},{"location":"guidelines/azure-devops-scrum/customisation/","text":"Customisation of WITs \u00b6 In order to gain maximum MI from Azure DevOps, some customisation has been made to WITs and the Process Flow. These are listed here; WIT Changes \u00b6 PBI \u00b6 Date Change Why Changed By Approved By Task \u00b6 Date Change Why Changed By Approved By Bug \u00b6 Date Change Why Changed By Approved By 03/07/2017 Removed 'Remaining Work' from Bug template To track hours in tasks rather than bugs Richard Speirs Richard Speirs Impediment \u00b6 Date Change Why Changed By Approved By 13/03/2017 Added Impediment Source To track who forced an impediment on the team Richard Speirs Richard Speirs 13/03/2017 Added Impediment Category To see where the most time is being lost Richard Speirs Richard Speirs Process Flow Changes \u00b6 PBI \u00b6 Date Change Why Changed By Approved By Task \u00b6 Date Change Why Changed By Approved By Bug \u00b6 Date Change Why Changed By Approved By Impediment \u00b6 Date Change Why Changed By Approved By","title":"Customisation"},{"location":"guidelines/azure-devops-scrum/customisation/#customisation-of-wits","text":"In order to gain maximum MI from Azure DevOps, some customisation has been made to WITs and the Process Flow. These are listed here;","title":"Customisation of WITs"},{"location":"guidelines/azure-devops-scrum/customisation/#wit-changes","text":"","title":"WIT Changes"},{"location":"guidelines/azure-devops-scrum/customisation/#pbi","text":"Date Change Why Changed By Approved By","title":"PBI"},{"location":"guidelines/azure-devops-scrum/customisation/#task","text":"Date Change Why Changed By Approved By","title":"Task"},{"location":"guidelines/azure-devops-scrum/customisation/#bug","text":"Date Change Why Changed By Approved By 03/07/2017 Removed 'Remaining Work' from Bug template To track hours in tasks rather than bugs Richard Speirs Richard Speirs","title":"Bug"},{"location":"guidelines/azure-devops-scrum/customisation/#impediment","text":"Date Change Why Changed By Approved By 13/03/2017 Added Impediment Source To track who forced an impediment on the team Richard Speirs Richard Speirs 13/03/2017 Added Impediment Category To see where the most time is being lost Richard Speirs Richard Speirs","title":"Impediment"},{"location":"guidelines/azure-devops-scrum/customisation/#process-flow-changes","text":"","title":"Process Flow Changes"},{"location":"guidelines/azure-devops-scrum/customisation/#pbi_1","text":"Date Change Why Changed By Approved By","title":"PBI"},{"location":"guidelines/azure-devops-scrum/customisation/#task_1","text":"Date Change Why Changed By Approved By","title":"Task"},{"location":"guidelines/azure-devops-scrum/customisation/#bug_1","text":"Date Change Why Changed By Approved By","title":"Bug"},{"location":"guidelines/azure-devops-scrum/customisation/#impediment_1","text":"Date Change Why Changed By Approved By","title":"Impediment"},{"location":"guidelines/azure-devops-scrum/definition-of-done/","text":"Definition of Done \u00b6 Key to SCRUM teams is to have a clear Definition of Done \u2013 or DOD. It highlights the criteria that has to be met in order for a Product Backlog Item be marked as \u2018Done\u2019. Before any project starts, the DOD must be agreed by the Scrum Team (including Product Owner). The team should take the 5 compulsory DOD items and pick a minimum of 3 optional. Compulsory DOD Items \u00b6 Acceptance Criteria of Product Owner are met Azure DevOps updated - remaining hours for task(s) set to 0 and all sub-task(s) are closed Code is commented and checked in source control Code is Unit Tested Peer reviewed and meets development coding standards Optional DOD Items \u00b6 Functional Documentation ready Unit tests written and passing Deployed to Test Environment Passed UAT (User Acceptance Testing) and signed off as meeting requirements Component design created Builds without errors NFR\u2019s validated Release candidate built","title":"Definition of Done"},{"location":"guidelines/azure-devops-scrum/definition-of-done/#definition-of-done","text":"Key to SCRUM teams is to have a clear Definition of Done \u2013 or DOD. It highlights the criteria that has to be met in order for a Product Backlog Item be marked as \u2018Done\u2019. Before any project starts, the DOD must be agreed by the Scrum Team (including Product Owner). The team should take the 5 compulsory DOD items and pick a minimum of 3 optional.","title":"Definition of Done"},{"location":"guidelines/azure-devops-scrum/definition-of-done/#compulsory-dod-items","text":"Acceptance Criteria of Product Owner are met Azure DevOps updated - remaining hours for task(s) set to 0 and all sub-task(s) are closed Code is commented and checked in source control Code is Unit Tested Peer reviewed and meets development coding standards","title":"Compulsory DOD Items"},{"location":"guidelines/azure-devops-scrum/definition-of-done/#optional-dod-items","text":"Functional Documentation ready Unit tests written and passing Deployed to Test Environment Passed UAT (User Acceptance Testing) and signed off as meeting requirements Component design created Builds without errors NFR\u2019s validated Release candidate built","title":"Optional DOD Items"},{"location":"guidelines/azure-devops-scrum/glossary/","text":"Glossary \u00b6 This glossary defines key terms that are used in AGILE (SCRUM) TFS \u2013 Team Foundation Server PBI \u2013 Product Backlog Item DOD \u2013 definition of done CI - Continuous Integration WIT \u2013 Work Item Type PBR \u2013 Product Backlog Refinement PBI \u2013 Product Backlog Item ALM \u2013 Application Lifecycle Management","title":"Glossary"},{"location":"guidelines/azure-devops-scrum/glossary/#glossary","text":"This glossary defines key terms that are used in AGILE (SCRUM) TFS \u2013 Team Foundation Server PBI \u2013 Product Backlog Item DOD \u2013 definition of done CI - Continuous Integration WIT \u2013 Work Item Type PBR \u2013 Product Backlog Refinement PBI \u2013 Product Backlog Item ALM \u2013 Application Lifecycle Management","title":"Glossary"},{"location":"guidelines/azure-devops-scrum/scrum/","text":"SCRUM Process and Guides \u00b6 Introduction \u00b6 This document will provide the guidance, process flow and meetings involved to successfully develop and project manage using AGILE (SCRUM) methodology. Pre-Reading \u00b6 Any colleagues using the AGILE (SCRUM) methodology should watch these videos ( here and here ) and further reading is available on https://www.scrum.org and http://www.scrumguides.org Azure DevOps \u00b6 The Application Lifecycle Management tool of choice is Visual Studio Team Services (Azure DevOps) using the UoN SCRUM (v1.0) process template. Azure DevOps web access can be accessed here; https://dev.azure.com/UniversityOfNottingham Roles and Responsibilities \u00b6 Within SCRUM, there are 3 key roles. Described below is the summary of responsibly for these roles. Further reading can be found online. Scrum Master \u00b6 This role ensures that the values of Scrum are upheld. They would mentor all roles and members of the team on the objectives of Scrum and the best way to achieve the right outcome. They organise and facilitate all the meetings, as well as take notes and feedback to the team any outcomes. They are responsible for the maintenance of the capacity planning, task board and burn down. This role closest matches that of a Business Analyst. Product Owner \u00b6 This role is key to delivering the project to time and cost. This role is akin to the classic Project Manager role. They are the only interface between the stakeholders and the scrum team and should act as a buffer between the two. They will understand the vision of the stakeholder and be able to share with the scrum team and guide all key non-technical decision. The PO should prioritise the Product Backlog and ensure that it has all the detail needed for the scrum team to make it a success. Scrum (Development) Team \u00b6 These are the team members responsible for setting and achieving the deliverables within an agreed sprint window. They should, with the PO, agree the PBIs that can be completed within a sprint. They should breakdown Product Backlog Items (PBIs) into tasks that must be achieved within a sprint window. This team would be multifunctional and be able to demonstrate the outputs from the sprint at the end during the Sprint Retrospective. Meeting Structure \u00b6 SCRUM process dictates a number of meetings should be held. These are as follows; Product Backlog Refinement (Grooming) \u00b6 Who: Entire team When: Mid sprint Length: 4 hours (time-boxed) This will inform our target backlog for the next sprint and should make the subsequent sprint planning session run a lot smoother. PBR sessions are typically lead by the PO. Agenda as follows: Ensure product backlog is in correct priority order in conjunction with the Product Owner (PO) Make sure that PBIs that can be worked on by the team are marked as \u201cApproved\u201d Take each product backlog item / bug and update it with any new information we have. This includes updating the following: The PBI title Description Acceptance criteria Any supporting diagrams / attachments Example data Test cases Creation of bucket-tasks for PBIs to speed up next sprint planning session Score PBI\u2019s effort (SCRUM poker) Break down any PBI\u2019s that are too large Review PBIs with completed tasks but not yet marked as \u201cDone\u201d General housekeeping \u2013 make sure PBIs/Bugs have someone assigned and that none have fallen between the cracks Sprint Planning \u00b6 Who: Entire team When: Mid sprint Length: 8 hours (time-boxed) This session should last no more than 1\u00bd hours for a SCRUM team of 3 - but can be upto a full day for a larger SCRUM team. The meeting ends with the teams tasking-out in their own areas back at their desks if not completed in the meeting. Agenda as follows: Review retrospective action plan agreed Set our capacity, taking into account any planned leave / other project conflicts Review as a team the product backlog and make any small priority amends (note that the priority should have been set by the PO prior to this meeting) Agree as a team the target product backlog items to be moved to the next sprint based on a sensible velocity taken from previous sprints / experience Clarify PBIs where anyone feels the requirements aren\u2019t clear enough Daily Scrum (The Stand-Up) \u00b6 Who: Development team When: Daily at the same time Length: 15 mintes (time-boxed) You don\u2019t need a room for this, but there should be a single place where everyone is agreed and can meet every morning to complete. Observers are welcomed in a 'chicken\u2019 capacity. Go around in a circle with 3 simple questions. Agenda as follows: What did you do yesterday What are you going to do today Anything blocking you from completing the task Important to note that the SCRUM should be quick, simple and any blockers (or points of note), should be taken off-line by the PO to talk about after. Having lengthy conversations at this stage results in developers being in SCRUMS for 30 minutes whereby most of the group will have no influence (or care) on the outcome. Sprint Retrospective \u00b6 Who: Entire team When: End of Sprint Length: 1 hour Agenda as follows: Review this burndown against previous What went well / didn\u2019t go well Vote on which of the things that didn\u2019t go well we\u2019d like to change? 3 votes each. Agree action plan to fix the favourite. Plan to include What/How/Who will do it. Sample Meeting Timeline \u00b6 Below is a timeline indicative of using the above AGILE (SCRUM) meetings process during a 10 day (2 week) sprint. Week 1 Day 1 Day 2 Day 3 Day 4 Day 5 AM Sprint Planning Stand-Up Stand-Up Stand-Up Stand-Up --- --- --- --- --- --- Week 2 Day 6 Day 7 Day 8 Day 9 Day 10 AM Stand-Up Stand-Up Stand-Up Stand-Up Stand-Up PM Backlog Refinement Sprint Demo/Retro","title":"SCRUM"},{"location":"guidelines/azure-devops-scrum/scrum/#scrum-process-and-guides","text":"","title":"SCRUM Process and Guides"},{"location":"guidelines/azure-devops-scrum/scrum/#introduction","text":"This document will provide the guidance, process flow and meetings involved to successfully develop and project manage using AGILE (SCRUM) methodology.","title":"Introduction"},{"location":"guidelines/azure-devops-scrum/scrum/#pre-reading","text":"Any colleagues using the AGILE (SCRUM) methodology should watch these videos ( here and here ) and further reading is available on https://www.scrum.org and http://www.scrumguides.org","title":"Pre-Reading"},{"location":"guidelines/azure-devops-scrum/scrum/#azure-devops","text":"The Application Lifecycle Management tool of choice is Visual Studio Team Services (Azure DevOps) using the UoN SCRUM (v1.0) process template. Azure DevOps web access can be accessed here; https://dev.azure.com/UniversityOfNottingham","title":"Azure DevOps"},{"location":"guidelines/azure-devops-scrum/scrum/#roles-and-responsibilities","text":"Within SCRUM, there are 3 key roles. Described below is the summary of responsibly for these roles. Further reading can be found online.","title":"Roles and Responsibilities"},{"location":"guidelines/azure-devops-scrum/scrum/#scrum-master","text":"This role ensures that the values of Scrum are upheld. They would mentor all roles and members of the team on the objectives of Scrum and the best way to achieve the right outcome. They organise and facilitate all the meetings, as well as take notes and feedback to the team any outcomes. They are responsible for the maintenance of the capacity planning, task board and burn down. This role closest matches that of a Business Analyst.","title":"Scrum Master"},{"location":"guidelines/azure-devops-scrum/scrum/#product-owner","text":"This role is key to delivering the project to time and cost. This role is akin to the classic Project Manager role. They are the only interface between the stakeholders and the scrum team and should act as a buffer between the two. They will understand the vision of the stakeholder and be able to share with the scrum team and guide all key non-technical decision. The PO should prioritise the Product Backlog and ensure that it has all the detail needed for the scrum team to make it a success.","title":"Product Owner"},{"location":"guidelines/azure-devops-scrum/scrum/#scrum-development-team","text":"These are the team members responsible for setting and achieving the deliverables within an agreed sprint window. They should, with the PO, agree the PBIs that can be completed within a sprint. They should breakdown Product Backlog Items (PBIs) into tasks that must be achieved within a sprint window. This team would be multifunctional and be able to demonstrate the outputs from the sprint at the end during the Sprint Retrospective.","title":"Scrum (Development) Team"},{"location":"guidelines/azure-devops-scrum/scrum/#meeting-structure","text":"SCRUM process dictates a number of meetings should be held. These are as follows;","title":"Meeting Structure"},{"location":"guidelines/azure-devops-scrum/scrum/#product-backlog-refinement-grooming","text":"Who: Entire team When: Mid sprint Length: 4 hours (time-boxed) This will inform our target backlog for the next sprint and should make the subsequent sprint planning session run a lot smoother. PBR sessions are typically lead by the PO. Agenda as follows: Ensure product backlog is in correct priority order in conjunction with the Product Owner (PO) Make sure that PBIs that can be worked on by the team are marked as \u201cApproved\u201d Take each product backlog item / bug and update it with any new information we have. This includes updating the following: The PBI title Description Acceptance criteria Any supporting diagrams / attachments Example data Test cases Creation of bucket-tasks for PBIs to speed up next sprint planning session Score PBI\u2019s effort (SCRUM poker) Break down any PBI\u2019s that are too large Review PBIs with completed tasks but not yet marked as \u201cDone\u201d General housekeeping \u2013 make sure PBIs/Bugs have someone assigned and that none have fallen between the cracks","title":"Product Backlog Refinement (Grooming)"},{"location":"guidelines/azure-devops-scrum/scrum/#sprint-planning","text":"Who: Entire team When: Mid sprint Length: 8 hours (time-boxed) This session should last no more than 1\u00bd hours for a SCRUM team of 3 - but can be upto a full day for a larger SCRUM team. The meeting ends with the teams tasking-out in their own areas back at their desks if not completed in the meeting. Agenda as follows: Review retrospective action plan agreed Set our capacity, taking into account any planned leave / other project conflicts Review as a team the product backlog and make any small priority amends (note that the priority should have been set by the PO prior to this meeting) Agree as a team the target product backlog items to be moved to the next sprint based on a sensible velocity taken from previous sprints / experience Clarify PBIs where anyone feels the requirements aren\u2019t clear enough","title":"Sprint Planning"},{"location":"guidelines/azure-devops-scrum/scrum/#daily-scrum-the-stand-up","text":"Who: Development team When: Daily at the same time Length: 15 mintes (time-boxed) You don\u2019t need a room for this, but there should be a single place where everyone is agreed and can meet every morning to complete. Observers are welcomed in a 'chicken\u2019 capacity. Go around in a circle with 3 simple questions. Agenda as follows: What did you do yesterday What are you going to do today Anything blocking you from completing the task Important to note that the SCRUM should be quick, simple and any blockers (or points of note), should be taken off-line by the PO to talk about after. Having lengthy conversations at this stage results in developers being in SCRUMS for 30 minutes whereby most of the group will have no influence (or care) on the outcome.","title":"Daily Scrum (The Stand-Up)"},{"location":"guidelines/azure-devops-scrum/scrum/#sprint-retrospective","text":"Who: Entire team When: End of Sprint Length: 1 hour Agenda as follows: Review this burndown against previous What went well / didn\u2019t go well Vote on which of the things that didn\u2019t go well we\u2019d like to change? 3 votes each. Agree action plan to fix the favourite. Plan to include What/How/Who will do it.","title":"Sprint Retrospective"},{"location":"guidelines/azure-devops-scrum/scrum/#sample-meeting-timeline","text":"Below is a timeline indicative of using the above AGILE (SCRUM) meetings process during a 10 day (2 week) sprint. Week 1 Day 1 Day 2 Day 3 Day 4 Day 5 AM Sprint Planning Stand-Up Stand-Up Stand-Up Stand-Up --- --- --- --- --- --- Week 2 Day 6 Day 7 Day 8 Day 9 Day 10 AM Stand-Up Stand-Up Stand-Up Stand-Up Stand-Up PM Backlog Refinement Sprint Demo/Retro","title":"Sample Meeting Timeline"},{"location":"guidelines/azure-devops-scrum/wits/","text":"Work Item Types (WIT) \u00b6 WITs in UoN are defined by the SCRUM template we use. These are; Product Backlog Items (known as PBIs) Bugs Tasks Impediments The below terms definitions (and many more helpful definitions) and taken from https://www.scrumalliance.org Product Backlog Items \u00b6 In Scrum, a product backlog item (\"PBI\", \"backlog item\", or \"item\") is a unit of work small enough to be completed by a team in one Sprint iteration. Backlog items are decomposed into one or more tasks. A PBI workflow is as follows: Only the Product Owner should move the PBI through these stage gates. Bugs \u00b6 These represent a problem or potential problem in your solution. These can be raised by anyone and can be committed into a sprint by the agreement of the team The lifecycle of a bug is as follows; Tasks \u00b6 In Scrum, a sprint task (or task) is a unit of work generally between four and sixteen hours. Team members volunteer for tasks. They update the estimated number of hours remaining on a daily basis, influencing the sprint burndown chart. Tasks are contained by backlog items. Scrum literature encourages splitting a task into several if the estimate exceeds twelve hours. The stages of a task are as the below; Impediments \u00b6 Anything that prevents a team member from performing work as efficiently as possible is an impediment. Each team member has an opportunity to announce impediments during the daily Scrum meeting. The Scrum Master is charged with ensuring impediments get resolved. Scrum Masters often arrange sidebar meetings when impediments cannot be resolved on the spot in the daily Scrum meeting. Impediments definition \u00b6 Holiday that was taken at short notice, i.e. wasn\u2019t planned before the sprint was planned Any other kind of absence such as Sickness, compassionate leave, regardless of whether booked before the sprint was planned or not Planned department and Company meetings e.g. Staff IT Updates or away days Not impediments \u00b6 Project Team meetings relating to own product area, e.g. sprint planning, retro, review- Not an impediment, part of 1h/day slack Project Team meetings relating to project Sandy as a whole, e.g. Project Sandy update meeting - Not an impediment, part of 1h/day slack Holiday planned before the sprint \u2013 Not an impediment \u2013 Sprint capacity reduced to reflect this Planned Training\u2013 Not an impediment \u2013 Sprint capacity reduced to reflect this, or will be added as a task Planned Knowledge transfer\u2013 Not an impediment \u2013 Sprint capacity reduced to reflect this, or will be added as a task Doing general administration such as timesheets, expense claims, Changing IT equipment, desk moves, Payroll/Finance enquiries\u2026 Not an impediment, part of 1h/day slack May/may not be impediments depending on duration \u00b6 Working on emergency support issue \u2013 Firstly requires approval, then If > 0.5 hour then Impediment, if <= 0.5 hour, not an impediment, part of 1h/day slack Spending time with colleague(s) (walk up or in a meeting) also from Project to assist them on other matters relating to Project, but not relating to their current task- If > 0.5 hour then Impediment, if <= 0.5 hour, not an impediment, part of 1h/day slack Spending time with colleagues (walk up or in a meeting) not from Project to assist them- Firstly requires approval, then If > 0.5 hour then Impediment, if <= 0.5 hour, not an impediment, part of 1h/day slack Any other activity distracting you from your current task and not listed above - If > 0.5 hour then Impediment, if <= 0.5 hour, not an impediment, part of 1h/day slack Walk-ups / Meeting invitations from outside your projects \u00b6 No team member should expect support requests or walk ups from outside your project unless approved by your Product Owner. For walk ups inside your project, please use your discretion.","title":"WITS"},{"location":"guidelines/azure-devops-scrum/wits/#work-item-types-wit","text":"WITs in UoN are defined by the SCRUM template we use. These are; Product Backlog Items (known as PBIs) Bugs Tasks Impediments The below terms definitions (and many more helpful definitions) and taken from https://www.scrumalliance.org","title":"Work Item Types (WIT)"},{"location":"guidelines/azure-devops-scrum/wits/#product-backlog-items","text":"In Scrum, a product backlog item (\"PBI\", \"backlog item\", or \"item\") is a unit of work small enough to be completed by a team in one Sprint iteration. Backlog items are decomposed into one or more tasks. A PBI workflow is as follows: Only the Product Owner should move the PBI through these stage gates.","title":"Product Backlog Items"},{"location":"guidelines/azure-devops-scrum/wits/#bugs","text":"These represent a problem or potential problem in your solution. These can be raised by anyone and can be committed into a sprint by the agreement of the team The lifecycle of a bug is as follows;","title":"Bugs"},{"location":"guidelines/azure-devops-scrum/wits/#tasks","text":"In Scrum, a sprint task (or task) is a unit of work generally between four and sixteen hours. Team members volunteer for tasks. They update the estimated number of hours remaining on a daily basis, influencing the sprint burndown chart. Tasks are contained by backlog items. Scrum literature encourages splitting a task into several if the estimate exceeds twelve hours. The stages of a task are as the below;","title":"Tasks"},{"location":"guidelines/azure-devops-scrum/wits/#impediments","text":"Anything that prevents a team member from performing work as efficiently as possible is an impediment. Each team member has an opportunity to announce impediments during the daily Scrum meeting. The Scrum Master is charged with ensuring impediments get resolved. Scrum Masters often arrange sidebar meetings when impediments cannot be resolved on the spot in the daily Scrum meeting.","title":"Impediments"},{"location":"guidelines/azure-devops-scrum/wits/#impediments-definition","text":"Holiday that was taken at short notice, i.e. wasn\u2019t planned before the sprint was planned Any other kind of absence such as Sickness, compassionate leave, regardless of whether booked before the sprint was planned or not Planned department and Company meetings e.g. Staff IT Updates or away days","title":"Impediments definition"},{"location":"guidelines/azure-devops-scrum/wits/#not-impediments","text":"Project Team meetings relating to own product area, e.g. sprint planning, retro, review- Not an impediment, part of 1h/day slack Project Team meetings relating to project Sandy as a whole, e.g. Project Sandy update meeting - Not an impediment, part of 1h/day slack Holiday planned before the sprint \u2013 Not an impediment \u2013 Sprint capacity reduced to reflect this Planned Training\u2013 Not an impediment \u2013 Sprint capacity reduced to reflect this, or will be added as a task Planned Knowledge transfer\u2013 Not an impediment \u2013 Sprint capacity reduced to reflect this, or will be added as a task Doing general administration such as timesheets, expense claims, Changing IT equipment, desk moves, Payroll/Finance enquiries\u2026 Not an impediment, part of 1h/day slack","title":"Not impediments"},{"location":"guidelines/azure-devops-scrum/wits/#maymay-not-be-impediments-depending-on-duration","text":"Working on emergency support issue \u2013 Firstly requires approval, then If > 0.5 hour then Impediment, if <= 0.5 hour, not an impediment, part of 1h/day slack Spending time with colleague(s) (walk up or in a meeting) also from Project to assist them on other matters relating to Project, but not relating to their current task- If > 0.5 hour then Impediment, if <= 0.5 hour, not an impediment, part of 1h/day slack Spending time with colleagues (walk up or in a meeting) not from Project to assist them- Firstly requires approval, then If > 0.5 hour then Impediment, if <= 0.5 hour, not an impediment, part of 1h/day slack Any other activity distracting you from your current task and not listed above - If > 0.5 hour then Impediment, if <= 0.5 hour, not an impediment, part of 1h/day slack","title":"May/may not be impediments depending on duration"},{"location":"guidelines/azure-devops-scrum/wits/#walk-ups-meeting-invitations-from-outside-your-projects","text":"No team member should expect support requests or walk ups from outside your project unless approved by your Product Owner. For walk ups inside your project, please use your discretion.","title":"Walk-ups / Meeting invitations from outside your projects"},{"location":"guidelines/dotnet/fx-environment-setup/","text":"Legacy Applications developed on Windows only You'll want to install the following: The latest stable Visual Studio Enterprise edition Licensing (MSDN) You should have a MSDN Visual Studio Enterprise subscription - speak to a Team Lead for details Jetbrains Resharper (requires licensing - speak to a Senior Developer) Optional The latest stable SQL Server Management Studio (Current GA release) TODO - Guidance on what Visual Studio components to install You may find when you work on older applications you need earlier versions of Visual Studio, but we recommend installing these only when required. You may also wish to install preview versions of .NET tooling, such as Visual Studio betas or release candidates, or previews of SSMS. This is fine, but be cautious using preview versions, and always have the latest stable version installed as well.","title":".NET Framework Environment Setup"},{"location":"guidelines/dotnet/new-project/","text":"TODO - VS Code? other OSes? In Visual Studio on Windows \u00b6 If you are looking at creating a .Net Core Web App in Visual Studio, please follow the steps below: Create a new Solution. Select the ASP.Net Core Web Application option. Press next. Make sure you have selected the latest version of .Net Core (currently 2.0 as of 23/02/2018) Select empty - this makes it easier for us to add the standard bits that we need without worrying about introducing unused files. Front-end \u00b6 Note that this is only applicable if you have a UI! It is also worth noting that by default, if you did not create an empty project, that VS will use Bower to manage your front end packages. This is no longer recommended as Bower has been deprecated. TODO: the install node step isn't needed every time - it should be in environment setup Install node on system : either go to https://nodejs.org/en/download/ to install it directly, or if you want to use a command line package manager go to https://chocolatey.org/ By default, VS comes with its own version of node installed, but this is outdated. To use the version you installed on your system, select tools -> options -> projects and solutions -> web package management -> external web tools and add the location of node (default is C:\\Program Files\\nodejs ). Make sure this is at the top of the list. This only needs to be done once per system install, not project. Add the contents of the frontend folder of our boilerplate repo . package.json gulpfile.js Add a new folder to the project called \"js\" and add main.js from the boilerplate Add a new folder called \"sass\" add style.scss from boilerplate Other classes then need to go into their own folders (Controllers, Services, ViewModels, Entities etc). Some current examples of projects which follow our currently defined pattern are: OwnVehicles DECSYS.Survey SPMIC (revamp branch only)","title":"Starting a new Project"},{"location":"guidelines/dotnet/new-project/#in-visual-studio-on-windows","text":"If you are looking at creating a .Net Core Web App in Visual Studio, please follow the steps below: Create a new Solution. Select the ASP.Net Core Web Application option. Press next. Make sure you have selected the latest version of .Net Core (currently 2.0 as of 23/02/2018) Select empty - this makes it easier for us to add the standard bits that we need without worrying about introducing unused files.","title":"In Visual Studio on Windows"},{"location":"guidelines/dotnet/new-project/#front-end","text":"Note that this is only applicable if you have a UI! It is also worth noting that by default, if you did not create an empty project, that VS will use Bower to manage your front end packages. This is no longer recommended as Bower has been deprecated. TODO: the install node step isn't needed every time - it should be in environment setup Install node on system : either go to https://nodejs.org/en/download/ to install it directly, or if you want to use a command line package manager go to https://chocolatey.org/ By default, VS comes with its own version of node installed, but this is outdated. To use the version you installed on your system, select tools -> options -> projects and solutions -> web package management -> external web tools and add the location of node (default is C:\\Program Files\\nodejs ). Make sure this is at the top of the list. This only needs to be done once per system install, not project. Add the contents of the frontend folder of our boilerplate repo . package.json gulpfile.js Add a new folder to the project called \"js\" and add main.js from the boilerplate Add a new folder called \"sass\" add style.scss from boilerplate Other classes then need to go into their own folders (Controllers, Services, ViewModels, Entities etc). Some current examples of projects which follow our currently defined pattern are: OwnVehicles DECSYS.Survey SPMIC (revamp branch only)","title":"Front-end"},{"location":"standards/code-reviews/","text":"We regularly peer review all code. To ensure quality control and encourage collaboration and learning within the team, all projects are subject to mandatory code reviews throughout development. We use the Pull Request functionality in GitHub and Azure DevOps to review code. develop and master branches can only be merged into via Pull Request. Pull Requests must meet the following requirements to be merged. Automated Build and Testing pass. At least two reviewers approve (who are not an author of the changes being merged). All review comments must be resolved. What do we review? \u00b6 Check that the standards in this documentation are being followed Approved technologies Project structure Coding standards Git workflow, best practices Versioning CI builds Identify areas of code suitable for turning into future shared common code libraries","title":"Code Reviews"},{"location":"standards/code-reviews/#what-do-we-review","text":"Check that the standards in this documentation are being followed Approved technologies Project structure Coding standards Git workflow, best practices Versioning CI builds Identify areas of code suitable for turning into future shared common code libraries","title":"What do we review?"},{"location":"standards/continuous-integration/","text":"We use Azure DevOps to automate builds and testing of private repositories. We use [Travis-CI] to automate builds and testing of public repositories. All projects should have their build tasks completed automatically on pushes to most branches. master (and develop if applicable) must always be built all Pull Requests must require passing builds. Work In Progress branches should be built, unless consciously decided otherwise they should be opt-out, not opt-in What should CI builds do? CI builds should run all build tasks: Dependency management Linting Compilation Automated testing Preparing deployable artifacts CI builds should use Release (or Production ) configurations as a minimum. The CI server should ensure that code you plan to deploy builds and passes tests It's a bonus if it does the same for other configurations Deployment \u00b6 We do not use Continuous Deployment, but we deploy via Azure DevOps . Most of our applications are deployed by manually triggering a deployment to an environment on the CI / CD server. Deployments to Development environments (from the develop or master branch) can be continuous. Deployments to Test environments should be agreed with the Testing Team. They may be able to be continuous. Deployments to Production environments usually depend on gating by our Change Management process. Must be from master . Service Management will not approve Production releases from other branches. Ideally we prepare a release to Production once it has passed all other environments. The Service Management Team are then free to approve and schedule deployment of the release once all other conditions have been met. [Travis-CI] https://travis-ci.org","title":"Continuous Integration"},{"location":"standards/continuous-integration/#deployment","text":"We do not use Continuous Deployment, but we deploy via Azure DevOps . Most of our applications are deployed by manually triggering a deployment to an environment on the CI / CD server. Deployments to Development environments (from the develop or master branch) can be continuous. Deployments to Test environments should be agreed with the Testing Team. They may be able to be continuous. Deployments to Production environments usually depend on gating by our Change Management process. Must be from master . Service Management will not approve Production releases from other branches. Ideally we prepare a release to Production once it has passed all other environments. The Service Management Team are then free to approve and schedule deployment of the release once all other conditions have been met. [Travis-CI] https://travis-ci.org","title":"Deployment"},{"location":"standards/css/","text":"Tip Boilerplate configurations for CSS use can be found in the following repositories: General : https://github.com/UniversityOfNottingham/gulp-boilerplate .NET Core : https://github.com/UniversityOfNottingham/dotnet-boilerplate We write SASS in scss syntax. We don't specify complex rules. Our tooling configurations do that for us. Tooling \u00b6 Use SASS Lint to automatically enforce and check code quality. Use Prettier to enforce code style. Use node-sass to transpile to browser-supported code. Use Gulp to manage build tasks.","title":"CSS"},{"location":"standards/css/#tooling","text":"Use SASS Lint to automatically enforce and check code quality. Use Prettier to enforce code style. Use node-sass to transpile to browser-supported code. Use Gulp to manage build tasks.","title":"Tooling"},{"location":"standards/javascript/","text":"Tip Boilerplate configurations for JavaScript use can be found in the following repositories: General : https://github.com/UniversityOfNottingham/gulp-boilerplate .NET Core : https://github.com/UniversityOfNottingham/dotnet-boilerplate We write modern JavaScript, using the latest version of ES supported by Babel . We use ES6 module syntax, not CommonJS (i.e. import not require ). We don't specify complex rules. Our tooling configurations do that for us. Tooling \u00b6 Use npm to manage packages. Use ESLint to automatically enforce and check code quality. Use Prettier to enforce code style. Use Babel to transpile to browser-supported code. Use Gulp to manage build tasks. Doc Comments \u00b6 Use JSDoc for doc commenting, and building API documentation.","title":"JavaScript"},{"location":"standards/javascript/#tooling","text":"Use npm to manage packages. Use ESLint to automatically enforce and check code quality. Use Prettier to enforce code style. Use Babel to transpile to browser-supported code. Use Gulp to manage build tasks.","title":"Tooling"},{"location":"standards/javascript/#doc-comments","text":"Use JSDoc for doc commenting, and building API documentation.","title":"Doc Comments"},{"location":"standards/php/","text":"PHP conventions - order of priority. There are various sources of authority for PHP conventions, but they should be followed in the following order: PHP-FIG PSR-2 standards This documentation Where the answer isn't clear in this documentation then refer to the existing code in the file then the repository for clarity If no clear standard is found then this must be raised with a senior developer for the standards to be set in the documentation We use the latest version of PHP for new applications. We don't make new applications on old versions of PHP. We currently have older applications on PHP 5.6. We have legacy applications on unsupported versions of PHP. Function return \u00b6 Do not assign a value to a variable to immediately return it. //Bad return $result = $this->getResult(); //Bad $result = $this->getResult(); return $result; //Best return $this->getResult(); Unless the variable is being used or manipulated further in the function, it must not be assigned to a variable. Instead the result should be returned directly. The method name should be sufficient for callers to know exactly what will be returned.","title":"PHP"},{"location":"standards/php/#function-return","text":"Do not assign a value to a variable to immediately return it. //Bad return $result = $this->getResult(); //Bad $result = $this->getResult(); return $result; //Best return $this->getResult(); Unless the variable is being used or manipulated further in the function, it must not be assigned to a variable. Instead the result should be returned directly. The method name should be sufficient for callers to know exactly what will be returned.","title":"Function return"},{"location":"standards/target-platforms/","text":"We currently offer three platforms for solutions built by Application Development, and they should be chosen based on project needs: Each platform's own Standards and Guidelines must be followed. We use .NET Core .NET Core can be used to fulfill the following use cases: Client-facing Web Applications ASP.NET Core MVC Application / Integration APIs (over HTTP or WebSocket) ASP.NET Core MVC (no frontend) Scheduled tasks (when necessary) Console application We use PHP PHP can be used to fulfill the following use cases: Client-facing Web Applications Application / Integration APIs (over HTTP or WebSocket) We use SharePoint SharePoint can be used to fulfill the following use cases: Client facing Office 365 Apps Client-side Angular application We use node.js (internal only) Node JS may be used at the Senior Developers discretion for internal projects. Legacy platforms \u00b6 We still support and maintain some older applications on legacy platforms. New projects MUST NOT target these platforms. Windows Forms, WPF We don't use this anymore because: We prefer to write Web Applications. Supports Windows clients only. ASP.NET 4.x or earlier We don't use this anymore because: ASP.NET Core has succeeded it. It no longer gets adequate security updates and support. ASP.NET WebForms We don't use this anymore because: ASP.NET Core Razor Pages has succeeded it. It no longer gets adequate security updates and support. We have a lack of team expertise in this technology. Code behind convention encourages mixing of presentation and logic ASP.NET Core MVC serves the same use case: Client facing web apps in .NET Windows Communication Foundation (WCF) We don't use this anymore because: We have a lack of team expertise in this technology. ASP.NET Core MVC serves the same use case: Web Services over HTTP or WebSocket This could be reconsidered: If we have a need for web services over other transport protocols as per MSDN Classic ASP We don't use this anymore because: ASP.NET Core has succeeded it. It no longer gets adequate security updates and support. We have a lack of team expertise in this technology. Visual BASIC 6 We don't use this anymore because: We prefer to write Web Applications. Supports Windows clients only. It no longer gets adequate security updates and support. We have a lack of team expertise in this technology. Java We don't use this anymore because: We have a lack of broad team expertise in this technology. We lack modern processes and workflow in the team for this technology e.g. web frameworks, package management, web servers","title":"Target Platforms"},{"location":"standards/target-platforms/#legacy-platforms","text":"We still support and maintain some older applications on legacy platforms. New projects MUST NOT target these platforms. Windows Forms, WPF We don't use this anymore because: We prefer to write Web Applications. Supports Windows clients only. ASP.NET 4.x or earlier We don't use this anymore because: ASP.NET Core has succeeded it. It no longer gets adequate security updates and support. ASP.NET WebForms We don't use this anymore because: ASP.NET Core Razor Pages has succeeded it. It no longer gets adequate security updates and support. We have a lack of team expertise in this technology. Code behind convention encourages mixing of presentation and logic ASP.NET Core MVC serves the same use case: Client facing web apps in .NET Windows Communication Foundation (WCF) We don't use this anymore because: We have a lack of team expertise in this technology. ASP.NET Core MVC serves the same use case: Web Services over HTTP or WebSocket This could be reconsidered: If we have a need for web services over other transport protocols as per MSDN Classic ASP We don't use this anymore because: ASP.NET Core has succeeded it. It no longer gets adequate security updates and support. We have a lack of team expertise in this technology. Visual BASIC 6 We don't use this anymore because: We prefer to write Web Applications. Supports Windows clients only. It no longer gets adequate security updates and support. We have a lack of team expertise in this technology. Java We don't use this anymore because: We have a lack of broad team expertise in this technology. We lack modern processes and workflow in the team for this technology e.g. web frameworks, package management, web servers","title":"Legacy platforms"},{"location":"standards/version-control/","text":"We use Git Current applications should be version controlled in Git. Where are our Git repositories? Azure DevOps hosts our private git repositories GitHub hosts any public repositories. Git workflows \u00b6 We use two branch workflows for Git, depending on the needs of the project. We always use Pull Requests to merge into important branches. Which flow should I use? Use Master Branch Only If you're starting a new project Unless you've explicitly agreed with Senior Developers that Git Flow should be used. If you agree with the Senior Developers that it's time to transition the project to Master Branch Only . Use Git Flow If your project already uses Git Flow (i.e. it has a develop branch). Master Branch Only \u00b6 This workflow is simpler, and is based on GitHub Flow but has some caveats around the fact we don't continuously deploy to Production. For more detailed guidance, refer to the Guidelines and Processes sections for Git (coming soon). Your project must support versioning suitable for continuous release when using this workflow. Code that can be released from a single continuously integrated master branch must be able to automatically uniquely version a given code commit. Refer to versioning for more information. The master branch always contains the latest integrated version of the code. master is a protected branch, and can only acquire code via a pull request Releases to Production must come from master . Commits on master should always be considered safe to deploy. All other branches are work-in-progress branches. When work is complete: A version bump may occur, if the changes are meaningful enough to warrant it. A Pull Request is raised and reviewed merged into master , if review passes. All merges to master undergo automated builds and testing before and after they get there. They subsequently deploy to any number of pre production environments, for as many stages of testing as are necessary. Approval on an environment allows deployment to the next environment, up until Production. Release to Production is optional, but a release can be made from any merge to master . Git Flow \u00b6 Most of our projects use the popular Git Flow workflow, which details a sensible branching and merging model. We have slightly modified Git Flow to accomodate our Pull Request standards. For more detailed guidance, refer to the Guidelines and Processes sections for Git (coming soon). The master branch is either your initial commit ( readme.md , .gitignore ) or the current production verion of the code. master is a protected branch, and can only acquire code via a pull request Releases to Production must come from master . Releases to environments must be version tagged e.g. 1.6.0 The develop branch represents the code that will be going into the next release branch, whenever that happens develop is a protected branch, and can only acquire code via a pull request release branches are for preparing a release to test or production. Create a release branch when all development for a new release is finished and included in develop Use the release branch only to prepare for Production. The only changes on release branches should be bug fixes found during testing and changes to version numbering. Releases to Test environments must come from a release branch release branches should be named after the version they are preparing e.g. 1.7.0 Releases to environments must be tagged e.g. 1.7.0-beta1 When a release is ready for production: Make a pull request to merge to develop Make a pull request to merge to master Your release branch will then be code reviewed feature branches are for adding features or fixing bugs to go into the next version Create a feature branch when you start work on a specific task If there is a JIRA issue for the feature, put it in the branch name Only do work for this specific task in this branch. When you have completed the development work for the task: Make a pull request to merge to develop Your feature branch will then be code reviewed hotfix branches are for fixing urgent bugs to Production Create a hotfix branch when you start work on the bug Only fix the bug in question When you have completed the development work for the bug: Make a pull request to merge to master Make a pull request to merge to develop Your hotfix branch will then be code reviewed Legacy applications \u00b6 Some legacy applications are still in SVN or Visual SourceSafe. If any work is ever done on these applications, their source must be migrated to an appropriate Git repo.","title":"Version Control"},{"location":"standards/version-control/#git-workflows","text":"We use two branch workflows for Git, depending on the needs of the project. We always use Pull Requests to merge into important branches. Which flow should I use? Use Master Branch Only If you're starting a new project Unless you've explicitly agreed with Senior Developers that Git Flow should be used. If you agree with the Senior Developers that it's time to transition the project to Master Branch Only . Use Git Flow If your project already uses Git Flow (i.e. it has a develop branch).","title":"Git workflows"},{"location":"standards/version-control/#master-branch-only","text":"This workflow is simpler, and is based on GitHub Flow but has some caveats around the fact we don't continuously deploy to Production. For more detailed guidance, refer to the Guidelines and Processes sections for Git (coming soon). Your project must support versioning suitable for continuous release when using this workflow. Code that can be released from a single continuously integrated master branch must be able to automatically uniquely version a given code commit. Refer to versioning for more information. The master branch always contains the latest integrated version of the code. master is a protected branch, and can only acquire code via a pull request Releases to Production must come from master . Commits on master should always be considered safe to deploy. All other branches are work-in-progress branches. When work is complete: A version bump may occur, if the changes are meaningful enough to warrant it. A Pull Request is raised and reviewed merged into master , if review passes. All merges to master undergo automated builds and testing before and after they get there. They subsequently deploy to any number of pre production environments, for as many stages of testing as are necessary. Approval on an environment allows deployment to the next environment, up until Production. Release to Production is optional, but a release can be made from any merge to master .","title":"Master Branch Only"},{"location":"standards/version-control/#git-flow","text":"Most of our projects use the popular Git Flow workflow, which details a sensible branching and merging model. We have slightly modified Git Flow to accomodate our Pull Request standards. For more detailed guidance, refer to the Guidelines and Processes sections for Git (coming soon). The master branch is either your initial commit ( readme.md , .gitignore ) or the current production verion of the code. master is a protected branch, and can only acquire code via a pull request Releases to Production must come from master . Releases to environments must be version tagged e.g. 1.6.0 The develop branch represents the code that will be going into the next release branch, whenever that happens develop is a protected branch, and can only acquire code via a pull request release branches are for preparing a release to test or production. Create a release branch when all development for a new release is finished and included in develop Use the release branch only to prepare for Production. The only changes on release branches should be bug fixes found during testing and changes to version numbering. Releases to Test environments must come from a release branch release branches should be named after the version they are preparing e.g. 1.7.0 Releases to environments must be tagged e.g. 1.7.0-beta1 When a release is ready for production: Make a pull request to merge to develop Make a pull request to merge to master Your release branch will then be code reviewed feature branches are for adding features or fixing bugs to go into the next version Create a feature branch when you start work on a specific task If there is a JIRA issue for the feature, put it in the branch name Only do work for this specific task in this branch. When you have completed the development work for the task: Make a pull request to merge to develop Your feature branch will then be code reviewed hotfix branches are for fixing urgent bugs to Production Create a hotfix branch when you start work on the bug Only fix the bug in question When you have completed the development work for the bug: Make a pull request to merge to master Make a pull request to merge to develop Your hotfix branch will then be code reviewed","title":"Git Flow"},{"location":"standards/version-control/#legacy-applications","text":"Some legacy applications are still in SVN or Visual SourceSafe. If any work is ever done on these applications, their source must be migrated to an appropriate Git repo.","title":"Legacy applications"},{"location":"standards/versioning/","text":"Tip We use two versioning systems. One of them can be considered optional depending on the Git workflow in use. Semantic Versioning \u00b6 We use Semantic Versioning (\"SemVer\") SemVer provides application (or API) versions that contain meaningful semantic information by themselves. We use them so that developers, testers and, sometimes, users can compare version numbers and get a sense of the scope of the change. They are very much a public versioning system intended for humans . SemVer definition SemVer is a 3 part numeric version number, with an optional string label: MAJOR.MINOR.PATCH-label The numbers \u00b6 Increment MAJOR when you make incompatible (breaking) API changes. This is very rare for us in our client-facing applications, but more common in integration APIs and common code libraries. Increment MINOR when you new features / functionality but remain backwards compatible. Increment PATCH when you make bug fixes. The labels \u00b6 SemVer allows use of any labels for any purpose It is common to use alpha.X or beta.X (where X is an incrementing number) to pre-release version packages. Labels can be useful when deploying early releases from work-in-progress branches, to identify that the build is not intended to go into production. Continuous Versioning \u00b6 SemVer doesn't work for Continuous Deployment. SemVer is good practice, and provides useful version information to humans, but it breaks down in continuous release workflows, because the automated tooling responsible for releasing cannot make decisions about how meaningful code changes were, and therefore what effect they should have on a Semantic Version. Therefore, in addition to SemVer, we need another versioning system for use with such a workflow. When we use the Master Branch Only Git workflow, we are moving towards a Continuous Deployment attitude, and so any given commit in the master branch could be deployed to Production, and therefore must be uniquely and identifiably versioned. Typically, we use our CI system to provide a unique version for a given release; either a build or release number, or a git commit hash, or something similar. Ideally, applications will be able to report on this version as well as their human-friendly semantic version (which may not change with every release). The CI system should provide this capability. Tip Refer to Guidelines for versioning (coming soon) for examples of how this has been done on Master Branch Only projects to date. Version reporting \u00b6 We should always be able to find out the version of an application we have made, preferably without having to log in, but preferably not publicly visible all the time. Publicly accessibly Version reporting on demand Ideally, the version should be returned on request: from a public /version endpoint in web apps from a --version flag for the rare console apps. The returned version should be at least the SemVer complete with label. Refer to platform specific Standards and Guidelines for implementing version reporting. Version reporting in the front-end Our older web apps tend to have a version at the bottom of every page. This is acceptable for existing applications, but practically speaking most public users don't care what the version of an app is, so we should avoid this method in future. Version reporting requiring authentication Some of our web apps have a version page at an authenticated route, so we can confirm correct version deployment, but it's frustrating to have to log in.","title":"Versioning"},{"location":"standards/versioning/#semantic-versioning","text":"We use Semantic Versioning (\"SemVer\") SemVer provides application (or API) versions that contain meaningful semantic information by themselves. We use them so that developers, testers and, sometimes, users can compare version numbers and get a sense of the scope of the change. They are very much a public versioning system intended for humans . SemVer definition SemVer is a 3 part numeric version number, with an optional string label: MAJOR.MINOR.PATCH-label","title":"Semantic Versioning"},{"location":"standards/versioning/#the-numbers","text":"Increment MAJOR when you make incompatible (breaking) API changes. This is very rare for us in our client-facing applications, but more common in integration APIs and common code libraries. Increment MINOR when you new features / functionality but remain backwards compatible. Increment PATCH when you make bug fixes.","title":"The numbers"},{"location":"standards/versioning/#the-labels","text":"SemVer allows use of any labels for any purpose It is common to use alpha.X or beta.X (where X is an incrementing number) to pre-release version packages. Labels can be useful when deploying early releases from work-in-progress branches, to identify that the build is not intended to go into production.","title":"The labels"},{"location":"standards/versioning/#continuous-versioning","text":"SemVer doesn't work for Continuous Deployment. SemVer is good practice, and provides useful version information to humans, but it breaks down in continuous release workflows, because the automated tooling responsible for releasing cannot make decisions about how meaningful code changes were, and therefore what effect they should have on a Semantic Version. Therefore, in addition to SemVer, we need another versioning system for use with such a workflow. When we use the Master Branch Only Git workflow, we are moving towards a Continuous Deployment attitude, and so any given commit in the master branch could be deployed to Production, and therefore must be uniquely and identifiably versioned. Typically, we use our CI system to provide a unique version for a given release; either a build or release number, or a git commit hash, or something similar. Ideally, applications will be able to report on this version as well as their human-friendly semantic version (which may not change with every release). The CI system should provide this capability. Tip Refer to Guidelines for versioning (coming soon) for examples of how this has been done on Master Branch Only projects to date.","title":"Continuous Versioning"},{"location":"standards/versioning/#version-reporting","text":"We should always be able to find out the version of an application we have made, preferably without having to log in, but preferably not publicly visible all the time. Publicly accessibly Version reporting on demand Ideally, the version should be returned on request: from a public /version endpoint in web apps from a --version flag for the rare console apps. The returned version should be at least the SemVer complete with label. Refer to platform specific Standards and Guidelines for implementing version reporting. Version reporting in the front-end Our older web apps tend to have a version at the bottom of every page. This is acceptable for existing applications, but practically speaking most public users don't care what the version of an app is, so we should avoid this method in future. Version reporting requiring authentication Some of our web apps have a version page at an authenticated route, so we can confirm correct version deployment, but it's frustrating to have to log in.","title":"Version reporting"},{"location":"standards/dotnet/","text":"We use the latest stable version of C#. We target .NET Standard and .NET Core whenever possible. We follow the JavaScript and CSS standards when working with frontend code in a .NET environment. We maintain a list of approved technologies that solve common domain problems. Approved Technologies: .NET Core | .NET Framework Don't reinvent the wheel. Check the list to see if your problem is already solved; if not, still investigate third party libraries. Don't proliferate technologies unnecessarily. Don't introduce a new technology that solves a problem that's already solved on the list. We don't specify complex rules. Our tooling configurations do that for us. We don't write new code in other CLR Languages, such as Visual BASIC or F#. We have legacy applications written in VB.NET, or Classic VB. Tooling \u00b6 Use the latest stable version of Visual Studio . Use Resharper to automatically enforce and check code quality. Working with older projects. Upgrade the version of Visual Studio to the latest stable when possible Feel free to use new language features once upgraded But be consistent with the rest of the application where necessary Consider everyone (or everything) that builds the project. e.g. Make sure CI tools know how to build the new version. Doc Comments \u00b6 Use XML Doc Comments for doc commenting. Use Swagger with Swashbuckle for building and serving API documentation. Unit Testing \u00b6 Unit Testing is encouraged but not yet mandated. We use XUnit for unit testing. Some older .NET Framework applications have unit tests in Nunit 2.x or 3.x.","title":"Overview"},{"location":"standards/dotnet/#tooling","text":"Use the latest stable version of Visual Studio . Use Resharper to automatically enforce and check code quality. Working with older projects. Upgrade the version of Visual Studio to the latest stable when possible Feel free to use new language features once upgraded But be consistent with the rest of the application where necessary Consider everyone (or everything) that builds the project. e.g. Make sure CI tools know how to build the new version.","title":"Tooling"},{"location":"standards/dotnet/#doc-comments","text":"Use XML Doc Comments for doc commenting. Use Swagger with Swashbuckle for building and serving API documentation.","title":"Doc Comments"},{"location":"standards/dotnet/#unit-testing","text":"Unit Testing is encouraged but not yet mandated. We use XUnit for unit testing. Some older .NET Framework applications have unit tests in Nunit 2.x or 3.x.","title":"Unit Testing"},{"location":"standards/dotnet/c-sharp/","text":"This documentation supports and overrides Resharper's default C# conventions. C# conventions - order of priority. There are various sources of authority for C# conventions, but they should be followed in the following order: This documentation Resharper 's recommmendations Microsoft's Conventions and Guidelines Types \u00b6 Don't use arrays. Unless you have an exceptional reason. Justification The .NET Framework provides a whole host of optimised collection types; pick the one that's right for you. C# is a high level language; we shouldn't pre-emptively optimise on memory usage by managing fixed-size collections ourselves - 90% of the time the Framework knows best. Parameters and Return values should almost always return an interface , not a concrete type Use ICollection<> , IEnumerable<> , IDictionary<> , IQueryable<> etc. Don't use an array <>[] , and don't use List<> or another concrete implementation in the method signature. Public properties should usually be interface types, not concrete implementations especially if they are properties guaranteed by an interface Almost all collection variables in implementation code should be a .NET class type, not an array Use List<> , Dictionary<> , HashTable<> , Stack<> , Queue<> etc. Don't use an array <>[] If you absolutely want a fixed size collection because it makes your code clearer or less prone to error and it doesn't matter that it's a value type not a reference type , you may use an array. However, that sort of thing is usually only appropriate for high performance bare metal applications, or other low level code such as hardware emulators, drivers etc. That sort of code is not usually written in C#, and is almost never necessary in a web application. Usings \u00b6 Use top-level usings, not namespaced identifiers. //Bad System . Nullable < int > number ; //Better using System ; ... Nullable < int > number ; //Best int? number ; You should only have to provide namespaces in your actual code if you are clarifying an ambiguous reference: using System ; using Unity.Engine ; System . Random dotNetRandomNumberGenerator ; Unity . Engine . Random unityRandomNumberGenerator ; Identifiers \u00b6 Don't put redundant information in identifiers such as variable or method names. No Hungarian notation (the IDE tells you types!) some type names are common and this is acceptable, but be sensible: var person = new Person (); //Fine var personClass = new Person (); //Bad var personList = new List < Person >(); //Bad var people = new List < Person >(); //Good Variable Initialisation \u00b6 Don't bother assigning the default initial value to a variable. //Redundant bool myBool = false ; string myString = null ; MyObject myObject = null ; int myInt = 0 ; Do initialise collections, or object types before attempting to use their members. //Necessary var myList = new List < T >(); var myObject = new MyObject (); Don't use Constructor initialisation unless you need to run logic or accept parameters. public class MyClass { //Bad private bool _isAwesome ; public MyClass () { _isAwesome = true ; } ... //Good private bool _isAwesome = true ; //No default constructor needed! ... //Fine private bool _isAwesome public MyClass ( bool isAwesome ) { _isAwesome = isAwesome ; } //In C#6 and newer, you can do this for properties as well! public bool IsAwesome { get ; set ; } = true ; //No default constructor needed! } As before, don't bother setting members to their type's default values. Method declaration \u00b6 Use expression body syntax. From C#6, if the whole of your method is a single expression (a one line statement), you can use a shorter syntax. This is incredibly common in read service layers that simply call on a repository. //Pre C#6 public IEnumerable < Thing > GetAllTheThings () { return _thingRepo . List (); } //C#6 and newer public IEnumerable < Thing > GetAllTheThings () => _thingRepo . List ();","title":"C#"},{"location":"standards/dotnet/c-sharp/#types","text":"Don't use arrays. Unless you have an exceptional reason. Justification The .NET Framework provides a whole host of optimised collection types; pick the one that's right for you. C# is a high level language; we shouldn't pre-emptively optimise on memory usage by managing fixed-size collections ourselves - 90% of the time the Framework knows best. Parameters and Return values should almost always return an interface , not a concrete type Use ICollection<> , IEnumerable<> , IDictionary<> , IQueryable<> etc. Don't use an array <>[] , and don't use List<> or another concrete implementation in the method signature. Public properties should usually be interface types, not concrete implementations especially if they are properties guaranteed by an interface Almost all collection variables in implementation code should be a .NET class type, not an array Use List<> , Dictionary<> , HashTable<> , Stack<> , Queue<> etc. Don't use an array <>[] If you absolutely want a fixed size collection because it makes your code clearer or less prone to error and it doesn't matter that it's a value type not a reference type , you may use an array. However, that sort of thing is usually only appropriate for high performance bare metal applications, or other low level code such as hardware emulators, drivers etc. That sort of code is not usually written in C#, and is almost never necessary in a web application.","title":"Types"},{"location":"standards/dotnet/c-sharp/#usings","text":"Use top-level usings, not namespaced identifiers. //Bad System . Nullable < int > number ; //Better using System ; ... Nullable < int > number ; //Best int? number ; You should only have to provide namespaces in your actual code if you are clarifying an ambiguous reference: using System ; using Unity.Engine ; System . Random dotNetRandomNumberGenerator ; Unity . Engine . Random unityRandomNumberGenerator ;","title":"Usings"},{"location":"standards/dotnet/c-sharp/#identifiers","text":"Don't put redundant information in identifiers such as variable or method names. No Hungarian notation (the IDE tells you types!) some type names are common and this is acceptable, but be sensible: var person = new Person (); //Fine var personClass = new Person (); //Bad var personList = new List < Person >(); //Bad var people = new List < Person >(); //Good","title":"Identifiers"},{"location":"standards/dotnet/c-sharp/#variable-initialisation","text":"Don't bother assigning the default initial value to a variable. //Redundant bool myBool = false ; string myString = null ; MyObject myObject = null ; int myInt = 0 ; Do initialise collections, or object types before attempting to use their members. //Necessary var myList = new List < T >(); var myObject = new MyObject (); Don't use Constructor initialisation unless you need to run logic or accept parameters. public class MyClass { //Bad private bool _isAwesome ; public MyClass () { _isAwesome = true ; } ... //Good private bool _isAwesome = true ; //No default constructor needed! ... //Fine private bool _isAwesome public MyClass ( bool isAwesome ) { _isAwesome = isAwesome ; } //In C#6 and newer, you can do this for properties as well! public bool IsAwesome { get ; set ; } = true ; //No default constructor needed! } As before, don't bother setting members to their type's default values.","title":"Variable Initialisation"},{"location":"standards/dotnet/c-sharp/#method-declaration","text":"Use expression body syntax. From C#6, if the whole of your method is a single expression (a one line statement), you can use a shorter syntax. This is incredibly common in read service layers that simply call on a repository. //Pre C#6 public IEnumerable < Thing > GetAllTheThings () { return _thingRepo . List (); } //C#6 and newer public IEnumerable < Thing > GetAllTheThings () => _thingRepo . List ();","title":"Method declaration"},{"location":"standards/dotnet/packages/","text":"We bundle reusable code into NuGet packages. We publish packages to Nuget.org from Github whenever possible. We host packages that cannot be public on private feeds in Azure DevOps . Some older projects use older packages which are hosted on the private dotnet-legacy feed in Azure DevOps . UoN Packages \u00b6 Our common code packages are all in the UoN namespace. Standards for naming packages. Packages should be named (and namespaced) based on what they're used for. Sometimes this may make dependencies clear too. e.g. Common code for ASP.NET Web API is in the UoN.AspNet.WebApi project Common code for ASP.NET MVC5 would go in UoN.AspNet.Mvc Common code for authentication in ASP.NET Core would go UoN.AspNetCore.Authentication or possibly even further if it was specific to implementing a type of authentication: e.g. UoN.AspNetCore.Authentication.BasicAuth UoN Nuget packages target .NET Standard whenever possible. Try and target the lowest possible version that you require, in order to maximise compatibility. A library should only directly target a .NET implementation (i.e. Framework, Mono or Core) if it requires something that implementation provides that the others (or the netstandard spec) do not. This will almost never be true for us. Package code lives in its own Git respository. Each package should have its own repository. This makes versioning much easier. The repo can contain version controlled documentation for the library. It makes using Unit Test projects for individual libraries easier. If there are interdependencies on other UoN libraries, their packages (therefore specifically versioned) should be referenced. Packages should always use the Master Branch Only Git workflow. Packages are built and released via CI/CD. UoN.Common (deprecated) \u00b6 The UoN.Common packages are still available on Azure DevOps on the dotnet-legacy feed, as they are used by a number of existing applications. They should be considered deprecated and should not be used in new applications. If there is code in a UoN.Common package that has not been migrated to a new package, then please migrate it before use.","title":"NuGet Packages"},{"location":"standards/dotnet/packages/#uon-packages","text":"Our common code packages are all in the UoN namespace. Standards for naming packages. Packages should be named (and namespaced) based on what they're used for. Sometimes this may make dependencies clear too. e.g. Common code for ASP.NET Web API is in the UoN.AspNet.WebApi project Common code for ASP.NET MVC5 would go in UoN.AspNet.Mvc Common code for authentication in ASP.NET Core would go UoN.AspNetCore.Authentication or possibly even further if it was specific to implementing a type of authentication: e.g. UoN.AspNetCore.Authentication.BasicAuth UoN Nuget packages target .NET Standard whenever possible. Try and target the lowest possible version that you require, in order to maximise compatibility. A library should only directly target a .NET implementation (i.e. Framework, Mono or Core) if it requires something that implementation provides that the others (or the netstandard spec) do not. This will almost never be true for us. Package code lives in its own Git respository. Each package should have its own repository. This makes versioning much easier. The repo can contain version controlled documentation for the library. It makes using Unit Test projects for individual libraries easier. If there are interdependencies on other UoN libraries, their packages (therefore specifically versioned) should be referenced. Packages should always use the Master Branch Only Git workflow. Packages are built and released via CI/CD.","title":"UoN Packages"},{"location":"standards/dotnet/packages/#uoncommon-deprecated","text":"The UoN.Common packages are still available on Azure DevOps on the dotnet-legacy feed, as they are used by a number of existing applications. They should be considered deprecated and should not be used in new applications. If there is code in a UoN.Common package that has not been migrated to a new package, then please migrate it before use.","title":"UoN.Common (deprecated)"},{"location":"standards/dotnet/core/approved-technologies/","text":".NET Core is now the approved target platform for .NET Applications. Please do not create any new .NET Framework projects without discussing this with the Senior Developers . Approved Technologies The Senior Developers have discussed and chosen certain frameworks, libraries and technologies that we prefer to use as a solution for a given need or problem. Please consult this list when you are looking to solve a problem in your application, to see if we have a preferred way of doing things. This list can be debated and must evolve, but to see new technologies used or approved, the Senior Developers must be consulted and a case must be made. Technologies by use case \u00b6 These use cases include approved technologies notes on optional supporting libraries legacy technologies you might come across, but mustn't use on new apps. Active Directory User Authentication ASP.NET Identity Core UoN libraries for authentication and authorisation Local User Accounts ASP.NET Identity Core Entity Framework Core UoN libraries for authentication and authorisation Basic Authentication ZNetCS.AspNetCore.Authentication.Basic Probably used in conjunction with another Auth backend (e.g. Local or AD) Relational Database ORM Entity Framework Core Use Code First Migrations Inversion of Control (IoC) / Dependency Injection (DI) Microsoft.Extensions.DependencyInjection Autofac Only when doing more advanced DI that the above can't perform. Scheduled Tasks Hangfire Queued Tasks Hangfire Email sending Mailkit Configures and performs spec compliant email tasks such as sending over SMTP. SendGrid Configures and performs email sending via the SendGrid API. UoN.AspNetCore.RazorViewRenderer Renders a string as a Razor View, allowing for rich email templating. Error Logging SeriLog Unit Testing XUnit Moq JSON Newtonsoft.JSON Faceted Search Separate ElasticSearch instance Don't do search itself within .NET - interact with ES instead. Elastic Search.NET - low level client NEST - high level Elastic Search client Object mapping AutoMapper e.g. ViewModels -> DTOs -> Entities or vice versa Reading / writing CSV files CsvHelper Parsing and rendering Markdown Westwind.AspNetCore.Markdown supports rendering in Razor Views via a TagHelper supports parsing in C# and Razor using static methods Documentation","title":"Approved Technologies"},{"location":"standards/dotnet/core/approved-technologies/#technologies-by-use-case","text":"These use cases include approved technologies notes on optional supporting libraries legacy technologies you might come across, but mustn't use on new apps. Active Directory User Authentication ASP.NET Identity Core UoN libraries for authentication and authorisation Local User Accounts ASP.NET Identity Core Entity Framework Core UoN libraries for authentication and authorisation Basic Authentication ZNetCS.AspNetCore.Authentication.Basic Probably used in conjunction with another Auth backend (e.g. Local or AD) Relational Database ORM Entity Framework Core Use Code First Migrations Inversion of Control (IoC) / Dependency Injection (DI) Microsoft.Extensions.DependencyInjection Autofac Only when doing more advanced DI that the above can't perform. Scheduled Tasks Hangfire Queued Tasks Hangfire Email sending Mailkit Configures and performs spec compliant email tasks such as sending over SMTP. SendGrid Configures and performs email sending via the SendGrid API. UoN.AspNetCore.RazorViewRenderer Renders a string as a Razor View, allowing for rich email templating. Error Logging SeriLog Unit Testing XUnit Moq JSON Newtonsoft.JSON Faceted Search Separate ElasticSearch instance Don't do search itself within .NET - interact with ES instead. Elastic Search.NET - low level client NEST - high level Elastic Search client Object mapping AutoMapper e.g. ViewModels -> DTOs -> Entities or vice versa Reading / writing CSV files CsvHelper Parsing and rendering Markdown Westwind.AspNetCore.Markdown supports rendering in Razor Views via a TagHelper supports parsing in C# and Razor using static methods Documentation","title":"Technologies by use case"},{"location":"standards/dotnet/fx/approved-technologies/","text":".NET Framework is no longer an approved target platform. .NET Core should now take precedence. The Senior Developers will only approve the use of .NET Framework for projects that require it. Approved Technologies The Senior Developers have discussed and chosen certain frameworks, libraries and technologies that we prefer to use as a solution for a given need or problem. Please consult this list when you are looking to solve a problem in your application, to see if we have a preferred way of doing things. This list can be debated and must evolve, but to see new technologies used or approved, the Senior Developers must be consulted and a case must be made. Technologies by use case \u00b6 These use cases include approved technologies notes on optional supporting libraries legacy technologies you might come across, but mustn't use on new apps. Active Directory User Authentication ASP.NET Identity 2.x UoN libraries for authentication and authorisation Local User Accounts ASP.NET Identity 2.x Entity Framework 6.x UoN libraries for authentication and authorisation SQL Server Database ORM Entity Framework 6.x Use Code First Migrations for new projects NHibernate Dapper Inversion of Control (IoC) / Dependency Injection (DI) Castle.Windsor 3.x UoN libraries for dependency resolution Scheduled Tasks Hangfire Queued Tasks Hangfire Email sending Postal MVC5 Error Logging Elmah Unit Testing NUnit 3.x Moq NUnit 2.x JSON Newtonsoft.JSON Profiling Glimpse Has a plugin for Elastic Search too. Image Processing ImageResizer Sitemaps / Breadcrumbs MVC Sitemap Object mapping AutoMapper e.g. ViewModels -> DTOs -> Entities or vice versa Reading / writing CSV files CsvHelper","title":"Approved Technologies"},{"location":"standards/dotnet/fx/approved-technologies/#technologies-by-use-case","text":"These use cases include approved technologies notes on optional supporting libraries legacy technologies you might come across, but mustn't use on new apps. Active Directory User Authentication ASP.NET Identity 2.x UoN libraries for authentication and authorisation Local User Accounts ASP.NET Identity 2.x Entity Framework 6.x UoN libraries for authentication and authorisation SQL Server Database ORM Entity Framework 6.x Use Code First Migrations for new projects NHibernate Dapper Inversion of Control (IoC) / Dependency Injection (DI) Castle.Windsor 3.x UoN libraries for dependency resolution Scheduled Tasks Hangfire Queued Tasks Hangfire Email sending Postal MVC5 Error Logging Elmah Unit Testing NUnit 3.x Moq NUnit 2.x JSON Newtonsoft.JSON Profiling Glimpse Has a plugin for Elastic Search too. Image Processing ImageResizer Sitemaps / Breadcrumbs MVC Sitemap Object mapping AutoMapper e.g. ViewModels -> DTOs -> Entities or vice versa Reading / writing CSV files CsvHelper","title":"Technologies by use case"}]}